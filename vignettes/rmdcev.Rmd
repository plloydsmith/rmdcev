---
title: "Multiple Discrete-Continuous Extreme Value Model Estimation and Simulation in R: The rmdcev Package"
author:
  name: Patrick Lloyd-Smith
  affiliation: University of Saskatchewan
date: April 2019  #"`r format(Sys.time(), '%d %B %Y')`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Multiple Discrete-Continuous Extreme Value Model Estimation and Simulation in R: The rmdcev Package}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
#  html_document:
#    theme: flatly
#    highlight: haddock
#    toc: yes
#    toc_depth: 4
#    toc_float: yes
#    keep_md: true
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, cache = TRUE, dpi=300)
library(rmdcev)
library(dplyr)
```

## Abstract

This paper introduces the package **rmdcev** in R for estimation and simulation of multiple-discrete continuous extreme value (MDCEV) models with individual heterogeneity. The models supported by **rmdcev** are the MDCEV model, the latent class MDCEV model, and the random parameters MDCEV model. The models are fit using maximum likelihood estimation or Bayesian estimation. The **rmdcev** package also implements demand forecasting and welfare calculation for policy simulation. The purpose of this paper is to describe the MDCEV estimation and simulation framework and to demonstrate all the functionalities of **rmdcev**.

Keywords: multiple discrete-continuous extreme value, Kuhn-Tucker, latent class, random parameters, demand, welfare, preference heterogeneity, R.

## Introduction

Individual choice contexts are often characterized by both extensive (i.e. what alternative to choose) and intensive (i.e. how much of an alternative to consume) margins. These multiple discrete-continuous (MDC) choice situations are pervasive, arising in transportation, marketing, health, and decisions regarding environmental resources.
Kuhn-Tucker (KT) consumer demand models are often employed to analyze these MDC situations and substantial progress has been made on improving the econometric modeling structures. There is currently no available software package that

In addition to **rmdcev**, the [**apollo**](http://www.apollochoicemodelling.com/) package developed by Stephane Hess and David Palma at the Choice Modelling Centre in Leeds provides a flexible modelling platform for estimating MDCEV models and simulating demand behaviour. **apollo** estimates a full suite of discrete choice models and is thus more comprehensive then **rmdcev**. The main differences between the packages is that **rmdcev** 1) provides welfare simulation functions, 2) uses Stan program and NUTs sampling, 3) and implements the Kuhn-Tucker Linear Expenditure System utility specification \citep{von_haefen_kuhn-tucker_2005).

One reason cited for the lack of widespread use of these KT models is that applying these models for welfare analysis is not straightforward \citep{von_haefen_kuhn-tucker_2005, bhat_multiple_2014}. This issue is especially relevant in applying these models to studying decisions regarding environmental resources where producing welfare estimates is often the main purpose of the research.

I present a brief example below using **rmdcev** to estimate the MDCEV model and simulate welfare changes. The rest of the paper provides additional details.
Section 2 introduces the conceptual framework underlying MDCEV models and their connection to economic theory and welfare measures.

## Models

### Conceptual framework

Each individual $i$ maximizes utility through the choice of the numeraire good ($x_1$) and the non-numeraire alternatives ($x_k$) subject to a monetary budget constraint. We assume there is a numeraire good (i.e. essential Hicksian composite good) which is always consumed and has a price of one. The individual's maximization problem is

\begin{equation}
\max_{x_k, x_1} U(x_k, x_1) \; \;  \; \; s.t. \; \; y = \sum\limits^K_{k=2}p_k x_k + x_1,x_k \geq 0, k = 2,...,K  
\end{equation}

\noindent
where $x_k$ is the consumption level for alternative $k$, $x_1$ is consumption of the numeraire, $y$ is annual income, and $p_k$ is the unit price of alternative $k$.

The resulting first-order KT conditions that implicitly define the solution to the optimal consumption bundles of $x_k$ and $x_1$ are

\begin{eqnarray}
 \frac{U_{x_k}}{U_{x_1}} &\leq p_k,\; \; k = 1,....K,  \\
  x_k\left[\frac{U_{x_k}}{U_{x_1}} - p_k \right] &= 0,\; \; k = 1,....K.
\label{ktconditions}
\end{eqnarray}

For alternatives with positive consumption levels, the marginal rate of substitution between these alternatives and the numeraire good is equal to the price of the alternative. For unconsumed alternatives, the marginal rate of substitution between these alternatives and the numeraire good is less than the price of the alternatives.

These first-order conditions can be used to derive Marshallian and Hicksian demands and welfare measures. We assume that alternatives have non-price attribute $q_k$ and the vector of $k$ prices and attributes is denoted as $p^0$ and $q^$. The Hicksian compensating surplus ($CS^H$) for a change in price and quality from baseline levels $p^0$ and $q^0$ to new 'policy' levels $p^1$ and $q^1$ is defined explicitly using an expenditure function

\begin{align}
CS^H = y - e(p^1, q^1, \bar{U}, \theta, \varepsilon)
\label{welfare}
\end{align}

\noindent
where $\theta$ is the vector of structural parameters ($\psi_k, \alpha_k, \gamma_k$), $\varepsilon$ is a vector or matrix of unobserved heterogeneity, and $\bar{U} = V(p^0, q^0, y, \theta, \varepsilon)$ and represents baseline utility.

## Multiple Discrete-Continuous Extreme Value Model

Empirical analysis necessitates a
The **rmdcev** package implements the random utility specification as introduced by \cite{bhat2008multiple}. The utility function is specified as

\begin{equation}
\label{utilkt}
U(x_k, x_1) = \sum_{k=2}^{K} \frac{\gamma_k}{\alpha_k}\psi_k \left[ \left( \frac{x_k}{\gamma_k} + 1 \right)^{\alpha_k} - 1 \right] + \frac{\psi_1}{\alpha_1}x_1^{\alpha_1}
\end{equation}

\noindent
where $\gamma_k > 0$, $\psi_k > 0$ and $\alpha_k, \alpha_1 \leq 1$ for all $k$ are required for this specification to be consistent with the properties of a utility function \citep{bhat2008multiple}. Bhat (2008) provides an overview of the parameter interpretation and in brief

- The $\psi_k$ parameters represent the marginal utility of consuming alternative $k$ at the point of zero consumption (i.e. baseline marginal utility).
- The $\gamma_k$ parameters are translation parameters that allow for corner solutions (i.e. zero consumption levels for alternatives) and also influence satiation. The lower the value of $\gamma_k$, the more satiation effect in consuming $x_k$.
- The $\alpha$ parameters control the rate of diminishing marginal utility of additional consumption. If $\alpha_k$ equal to one, then there is no satiation effects (i.e. constant marginal utility).

The 'random utility' element of the model is introduced into the baseline utility through a random error term as

\begin{equation}
\psi_k=\psi(z_k,\varepsilon_k)= exp(\beta'z_k+\varepsilon_k)
\end{equation}

\noindent
where $\z_k$ is a set of variables that can include alternative-specific attributes and individual-specific characteristics, and $\varepsilon_k$ is an error term that allows for the utility function to be random over the population. We assume an extreme value distribution that is independently distributed across alternatives for $\varepsilon_k$ with an associated scale parameter of $\sigma$. For identification, we specify $\psi_1= e^{\varepsilon_1}$.

To ensure the estimated utility function corresponds to economic theory we specify the following parameterization:

- $\psi_k=exp(\beta'z_k+\varepsilon_k)$,
- $\gamma_k = exp(\gamma_k)$, and
- $\alpha_k = 1 - exp(\alpha_k)$.


Weak complementarity,  which is required for deriving unique welfare measures, is imposed in this specification by adding and subtracting one in the non-numeraire part of the utility function.

While the most general form of the MDCEV model includes 3 parameters for each alternative,
Bhat (2008) discusses the identification concerns regarding estimating separate $\gamma_k$ and $\alpha_k$ parameters for each non-numeraire alternative. Typically only a subset of these parameters can be identified and there are three common utility function specifications

1. $\alpha$-profile: set all $\gamma_k$ parameters to 1.

\begin{equation}
\label{utilkt_alpha}
U(x_k, x_1) = \sum_{k=2}^{K} \frac{1}{\alpha_k}exp(\beta'z_k+\varepsilon_k) \left[ \left( x_k + 1 \right)^{\alpha_k} - 1 \right] + \frac{exp(\varepsilon_1)}{\alpha_1}x_1^{\alpha_1}
\end{equation}

2. $\gamma$-profile: set all non-numeraire $\alpha_k$ parameters to 0.

\begin{equation}
\label{utilkt_gamma}
U(x_k, x_1) = \sum_{k=2}^{K} \gamma_k exp(\beta'z_k+\varepsilon_k) \ln\left( \frac{x_k}{\gamma_k} + 1 \right) + \frac{exp(\varepsilon_1)}{\alpha_1}x_1^{\alpha_1}
\end{equation}

3. Hybrid-profile: set all $\alpha_k=\alpha_1=\alpha$.

\begin{equation}
\label{utilkt_hybrid}
U(x_k, x_1) = \sum_{k=2}^{K} \frac{\gamma_k}{\alpha} exp(\beta'z_k+\varepsilon_k) \left[ \left( \frac{x_k}{\gamma_k} + 1 \right)^{\alpha_k} - 1 \right] + \frac{exp(\varepsilon_1)}{\alpha}x_1^{\alpha}
\end{equation}

The likelihood function representing the model probability of the consumption pattern where $M$ goods are chosen can be expressed as \citep{bhat2008multiple}

\begin{equation}
P(x^{*}_1,x^{*}_2...x^{*}_M,0,...,0) = \frac{1}{\sigma^{M-1}} \left(\prod_{m=1}^M c_m \right)\left(\sum_{m=1}^M \frac{p_m}{c_m} \right) \left( \ \frac{\prod_{m=1}^M e^{V_m/\sigma}}{ \left( \sum_{k=1}^J e^{V_k/\sigma} \right)^M }\right)(M-1)!
\label{ll_base}
\end{equation}

\noindent
where $\sigma$ is the scale parameter and $c_m = \frac{1-\alpha_m}{x_m+ \gamma_m}$. The $V$ expressions depend on what model specification is used:

1. $\alpha$-profle: $V_k = \beta' z_k + (\alpha_k-1)\ln\left( x_k + 1 \right) - \ln \left(p_k\right)$ for $k \geq 2$, and $V_1 = (\alpha_1-1)\ln(x_1)$.

2. $\gamma$-profle: $V_k = \beta' z_k - \ln\left( \frac{x_k}{\gamma_k} + 1 \right) - \ln \left(p_k\right)$ for $k \geq 2$, and $V_1 = (\alpha_1-1)\ln(x_1)$.

3. Hybrid-profile: $V_k = \beta' z_k + (\alpha-1)\ln\left( \frac{x_k}{\gamma_k} + 1 \right) - \ln \left(p_k\right)$, and $V_1 = (\alpha-1)\ln(x_1)$.

The parameters ($\beta, \alpha_k , \gamma_k, \sigma$) are structural parameters that are assumed to be equal across the population which simplifies estimation. However, this fixed MDCEV specification is quite restrictive as it imposes preference homeogeneity. This assumption is relaxed in the next two specifications.


## Latent Class MDCEV

The latent class version of the MDCEV assumes that an individual belongs to a finite mixture of $S$ segments each indexed by $s$ ($s=1,2,...S$). We do not observe which segment an individual belongs to but we can attribute a probability $\pi_{is}$ that individual $i$ is a member of segment $s$. We impose that $0 \leq \pi_{is} \leq 1$ and $\sum^S_{s=1} \pi_{is} = 1$ through the use of the logit link function as

$$\begin{equation}
\pi_{is} = \frac{exp(\delta_s'w_i)}{\sum^S_{s=1}exp(\delta_s'w_i)}
\end{equation}$$

\noindent
where $w_i$ is a vector of individual characteristics and $\delta_s$ is a vector of coefficients to be estimated. The $\delta_s$ coefficients determine how the individual characteristics affect the membership of individual $i$ in segment $s$. For identification, the $\delta_1$ coefficients for the first segment are set to zero.

The likelihood function can be

\begin{equation}
P = \prod_{i} \pi_{is}P_{is}
\end{equation}
where $P_{is}$ is now class specific and has the same form as Eq \ref{ll_base}.

## Random parameters

The random parameter specification of the MDCEV model assumes that the structural parameters ($\beta, \alpha_k , \gamma_k$) are distributed multivariate normal. This involves estimating the

$\sigma$ is assumed to be a fixed parameter.

The Bayesian framework is appealing for estimation due to the large number of parameters to be estimated.

Bernstein-von Mises theorem suggests that Bayesian posterior
mean estimates, interpreted within the classical framework, are asymptotically
equivalent to their classical maximum likelihood counterparts when the analyst
has correctly specified the data generating process. Following Train (2003), we
interpret this result as suggesting that both approaches should generate qualitatively
similar inference, and thus the analystâ€™s choice of which to use in
practice can be driven by computational convenience. We therefore discuss
estimation of the more restrictive specifications in the classical framework and
estimation of the more general specification in the Bayesian framework.

## The rmdcev package

### Data format

The **rmdcev** package accepts data in "long" format (one row per available non-numeraire alternative). There is no row for the numeraire good. The following named columns are required in the data:

- **id**: The unique id variable for each individual
- **good**: The variable containing the good number
- **quant**: Consumption levels for each good
- **price**: Price levels for each good
- **income**: Income level for each individual

Additional variables for alternative attributes or individual characteristics can also be included. Data must be arranged by id and then good.

As an example, we can load the recreation data incorporated with the package. This data is from the Value of Nature to Canadians Survey and includes choices for number of days spent recreating in 17 different outdoor activities for 2,000 people.

```{r, data}
data(data_rec, package = "rmdcev")
data_rec
```
The data includes information on three individual characteristics: university (a dummy variable if the person has completed a university degree), ageindex (a person's age divided by the average age in sample), and urban (a dummy variable if a person lives in an urban area). Additional details on the data and price construction are provided in Lloyd-Smith (2019). The names for each activity are provided in the good_name column. We can summarize the average consumption and price levels for each good as:

```{r, summary}
library(dplyr)
data_rec %>%
	group_by(good, good_name) %>%
	summarise(mean_quant = mean(quant),
			  mean_price = mean(price))
```



###	Formula interface

The $z_k$ variables can be specified using the **psi_formula** interface. This formula is based on the R package **Formula** (Zeileis and Crossiant, 2010).

```r
psi_formula = ~ z1 + z2 + z3
```

The formula will automatically include a constant but a constant can be omitted if -1 is used in the formula.

### Estimating MDCEV using Maximum Likelihood Techniques

We estimate a MDCEV model using the **Recreation** data where we include activity-specific constants (ASCs) in the $\psi$ parameter. To create the ASC data, we can use the following code to create indicator variables. Note that we can also use the factor(good_name) command directly in the formula but the names are quite long.

```{r, create_dummies}
data_rec <- data_rec %>%
  mutate(v = 1, yr = good_name) %>%
  tidyr::spread(yr, v, fill = 0) %>%
	arrange(id, good)
```

We specify the $\gamma$ model specification where a single $\alpha$ is estimated by setting model = "gamma". We use maximum likelihood estimation by setting algorithm = "MLE".

The syntax for the model is the following:

```{r, estimation_mdcev_gamma}
mdcev_mle <- FitMDCEV(psi_formula = ~ beach + birding + camping + cycling + fish + garden + golf +
                        hiking + hunt_birds + hunt_large + hunt_trap + hunt_waterfowl + motor_land +
                        motor_water + photo + ski_cross + ski_down -1,
                        data = subset(data_rec, id < 500),
                        model = "gamma0",
                        algorithm = "MLE",
                        print_iterations = FALSE)
```

The function first checks the data to ensure it has the neccesary variables, is arranged properly, and that all individuals in the data set spend positive amounts on the numeraire good. If the data passes these checks, the model is then estimated. Setting print_iterations = TRUE will print out intermediate iteration results as the model converges.

The output of the function can be accessed by calling SummaryMDCEV.

```{r, summary_mdcev_gamma}
SummaryMDCEV(mdcev_mle)
```

The summary includes overall information on the model and the parameter estimates.

There are four possible model options

- "les": Linear expenditure system with one estimated $\alpha_1$ and all non-numeraire $\alpha$ parameters equal to 1.
- "alpha": $\alpha$-profile with all $\gamma_k$ fixed equal to 1.
- "gamma": $\gamma$-profile with a single estimated $\alpha$ (i.e. $\alpha_1 = \alpha_k = \alpha$).
- "gamma0": $\gamma$-profile with all  $\alpha$ fixed equal to 1e-6.


### Estimating MDCEV using Bayesian Techniques

The exact same model can be fit using Bayesian estimation by changing the algorithm call to "Bayes". The Bayesian framework requires choice of priors for the parameters and these can be specified in the model command.

prior_psi_sd standard deviation for normal prior with mean 0.
prior_gamma_sd standard deviation for normal prior with mean 0.
prior_alpha_sd standard deviation for normal prior with mean 0.5.
prior_scale_sd standard deviation for normal prior with mean 1.

The number of iterations (n_iterations), number of chains (n_chains), and number of cores (n_cores) for parallel implementation of the chains can also be chosen.

```{r, estimation_mdcev_bayes}
mdcev_bayes <- FitMDCEV(psi_formula = ~ beach + birding + camping + cycling + fish + garden + golf +
                        hiking + hunt_birds + hunt_large + hunt_trap + hunt_waterfowl + motor_land +
                        motor_water + photo + ski_cross + ski_down -1,
                        data = subset(data_rec, id < 500),
                        model = "gamma0",
                        algorithm = "Bayes",
                        n_iterations = 100,
                        n_chains = 1,
                        print_iterations = FALSE)
```

The output of the function can be accessed by calling SummaryMDCEV.

```{r, summary_mdcev_bayes}
	SummaryMDCEV(mdcev_bayes)
```


One benefit of using the Bayesian approach is that we can take advantage of the postestimation commands, interactive diagnostics and posterior analysis in **rstan**, [**bayesplot**](https://mc-stan.org/bayesplot/), and [**shinystan**](http://mc-stan.org/shinystan/).

Include example with traceplot, pairs plot, posterior plot

### Estimating Latent Class MDCEV Models

In this example, we estimate a LC model using the **Recreation** data. We set the number of classes equal to 2. We would like to include the *university*, *ageindex*, and *urban* in the membership equation and we include them in the **lc_formula** interface. Note that we need to include at least a constant in the formula. The LC model is automatically estimated as long as the prespecified number of classes (**n_classes**) is set greater than 2.

```{r, estimation_mdcev_lc}
mdcev_lc <- FitMDCEV(psi_formula = ~ beach + birding + camping + cycling + fish + garden + golf +
                                  hiking + hunt_birds + hunt_large + hunt_trap + hunt_waterfowl +
                                  motor_land + motor_water + photo + ski_cross + ski_down - 1,
                                  lc_formula = ~ university + ageindex + urban,
                                  data = subset(data_rec, id < 500),
                                  n_classes = 2,
                                  model = "gamma0",
                                  algorithm = "MLE",
                                  print_iterations = FALSE)
```

```{r, summary_mdcev_lc}
	SummaryMDCEV(mdcev_lc)
```

In this LC example, we assume that there are two types of people that have different preferences for recreation. The probability of class assignment depends on unobserved factors and the three sociodemographic factors included in the membership equation

### Estimating Random Parameters MDCEV

*too come*


```{r, estimation_mdcev_rp}
mdcev_rp <- FitMDCEV(psi_formula = ~ beach + birding + camping + cycling + fish + garden + golf +
                                    hiking + hunt_birds + hunt_large + hunt_trap + hunt_waterfowl +
                                    motor_land + motor_water + photo + ski_cross + ski_down - 1,
                                    data = subset(data_rec, id < 500),
                                    model = "gamma0",
                                    algorithm = "Bayes",
                                    n_chains = 1,
                                    n_iterations = 10,
                                    random_parameters = "uncorr",
                                    print_iterations = FALSE)
```

## Rmdcev Demand and Welfare Simulation

The **rmdcev** package includes simulation functions for forecasting demand and calculating welfare measures. I first provide an overview of the approach used for simulation and then provide code examples.

There are two steps to simulation approach. In the first step we draw simulated values for the unobserved heterogeneity term ($\varepsilon$) using Monte Carlo simulation techniques. The second step uses these draws, model parameters and the data to calculate Marhsallian demands for forecasting or Hicksian demands for welfare analysis.

### Step 1: Simulating unobervered heterogeneity

Monte Carlo simulation techniques can be employed to draw simulated values of the unobserved heterogeneity ($\varepsilon$) using either unconditional or conditional draws.

1. Unconditional error draws: draw from the entire distribution of unobserved heterogeneity using the following formula

$\varepsilon_{k} = -log(-log(draw(0,1)))) * \sigma$

where $draw(0,1)$ is a draw between 0 and 1 and $\sigma$ is the scale parameter. **rmdcev** allows errors to be drawn using uniform draws or the Modified Latin Hypercube Sampling algorithm (Hess et al., 2006).

2. Conditional error draws: draw errors to reflect behaviour and dependent on whether alternative is consumed or not

- If $x_k>0$, set  $\varepsilon_k = (V_1 - V_k)/ \sigma$ where $V_1$ and $V_k$ depend on the model specification as detailed above.
- If $x_k=0$, $\varepsilon_k < (V_1 - V_k)/ \sigma$ and we can simulate $\varepsilon_k$ from the truncated type I extreme value distribution such that

$\varepsilon_k = -log(-log(draw(0, 1) * exp(-exp(\frac{v1 - vk}{\sigma})))) * \sigma$

In both cases, we normalize $\varepsilon_1=0$.

In the conditional approach, we draw errors such that the model perfectly predicts the observed consumption patterns in the baseline state \citep{von_haefen_kuhn-tucker_2005}. Thus the conditional approach uses observed behaviour by individuals to characterize unobserved heterogeneity. If the model correctly specifies the data generating process, the sample means of the conditional and unconditional approaches should converge in expectation. Another difference is more computational as the conditional error draws avoids the need to calculate consumption patterns in the baseline state as well as simulate the entire distribution of unobserved heterogeneity.

### Step 2: Calculating Demand and Welfare measures

With the error draws in hand, the second step is to simulate demand or welfare. **rmdcev** implements the Pinjari and Bhat (2011) demand forecasting routine for simulating demand behaviour and the approach described by Lloyd-Smith (2017) for welfare calculations.

#### Marshallian Demand

Pinjari and Bhat (2011)

```{r, sim_mdcev_demand}
	npols <- 2
	policies <-	CreateBlankPolicies(npols, mdcev_mle$stan_data[["J"]], mdcev_mle$stan_data[["dat_psi"]])
	policies$price_p[[1]] <- c(0, rep(5,mdcev_mle$stan_data[["J"]]))
	policies$price_p[[2]] <- c(0, rep(10,mdcev_mle$stan_data[["J"]]))
	df_sim <- PrepareSimulationData(mdcev_mle, policies)

#	demand <- SimulateMDCEV(df_sim$df_indiv, df_common = df_sim$df_common, sim_options = df_sim$sim_options,
#						 cond_err = 1, nerrs = 20, sim_type = "demand")

```

#### Welfare Analysis

```{r, sim_mdcev_welfare_setup}
	npols <- 2
	policies <-	CreateBlankPolicies(npols, mdcev_mle$stan_data[["J"]], mdcev_mle$stan_data[["dat_psi"]])
	policies$price_p[[1]] <- c(0, rep(1,mdcev_mle$stan_data[["J"]]))
	policies$price_p[[2]] <- c(0, rep(5,mdcev_mle$stan_data[["J"]]))
	df_sim <- PrepareSimulationData(mdcev_mle, policies)
```


```{r eval=F, echo=T, sim_mdcev_welfare}
	wtp <- SimulateMDCEV(df_sim$df_indiv, df_common = df_sim$df_common, sim_options = df_sim$sim_options,
						 cond_err = 1, nerrs = 15, sim_type = "welfare")
	SummaryWelfare(wtp)
```

Lloyd-Smith (2017)

## Modelling notes



## Conclusions

The **rmdcev** package implements the MDCEV . In this paper, we have demonstrated the use of the pacakage to estimate several model specifications and to derive welfare.

## Appendix



### Specific steps in algorithm for hybrid-profile utility functions

**Step 0**: Assume that only the numeraire alternative is chosen and let the number of chosen alternatives equal one (M=1).

**Step 1**: Using the data, model parameters, and either conditional or unconditional simulated error term draws, calculate the price-normalized baseline utility values ($\psi_k/p_k$) for all alternatives. Sort the $K$ alternatives in the descending order of their price-normalized baseline utility values. Note that the numeraire alternative is in the first place. Go to step 2.

**Step 2**: Compute the value of $\lambda^E$ using the following equation:

\begin{align}
\label{lambdaE}
\frac{1}{\lambda^E} = \left[ \frac{\alpha \bar{U} + \sum_{m=2}^{M} \gamma_m \psi_m} {\sum_{m=2}^{M} \gamma_m \psi_m \left( \frac{p_m}{\psi_m} \right)^\frac{\alpha}{\alpha-1} + \psi_1 \left(\frac{p_1}{\psi_1} \right)^\frac{\alpha}{\alpha-1}} \right] ^\frac{\alpha-1}{\alpha}.
\end{align}

Go to step 3.

**Step 3**: If $\frac{1}{\lambda^E} > \frac{\psi_{M+1}}{p_{M+1}}$, go to step 4. Else if $\frac{1}{\lambda^E} < \frac{\psi_{M+1}}{p_{M+1}}$, set $M = M + 1$. If $M < K$, go back to step 2. If $M = K$, go to step 4.

**Step 4**: Compute the optimal Hicksian consumption levels for the first $I$ alternatives in the above descending order using the following equations

\begin{align}
\begin{split}
\label{foc13}
x_1 &=   \left( \frac{p_1}{\lambda^E \psi_1} \right)^\frac{1}{\alpha_1-1}\text{, and} \\
x_m &=   \left[ \left( \frac{p_m}{\lambda^E \psi_m} \right)^\frac{1}{\alpha_m-1}-1 \right]\gamma_m, \; \; \text{if} \; \; x_m > 0.
\end{split}
\end{align}

Set the remaining alternative consumption levels to zero and stop.

### Specific steps in algorithm for general utility functions:

In the more general case of a utility function with different $\alpha_k$ parameters for each alternative, I modify the algorithm in Section 3.2. In this context, there is no closed-form expressions for $\lambda^E$ and I need to conduct a numerical bisection routine. Let $\hat{\lambda^E}$ and $\hat{U}$ be estimates of $\lambda^E$ and $U$ and let $tol_{\lambda}$ and $tol_{U}$ be the tolerance levels for estimating $\lambda^E$ and $U$ that can be arbitrarily small.

**Step 0**: Assume that only the numeraire is chosen and let the number of chosen alternatives equal one (M=1).

**Step 1**: Using the data, model parameters, and either conditional or unconditional simulated error term draws, calculate the price-normalized baseline utility values ($\psi_k/p_k$) for all alternatives. Sort the $K$ alternatives in the descending order of their price-normalized baseline utility values. Note that the numeraire is in the first place. Go to step 2.

**Step 2**: Let $\frac{1}{\hat{\lambda^E}} = \frac{\psi_{M+1}}{p_{M+1}}$ and substitute $\hat{\lambda^E}$ into the following quation to obtain an estimate of $\hat{U}$.

\begin{align}
\bar{U}=\sum_{M=2}^{M} \frac{\gamma_m}{\alpha_m}\psi_m \left[ \left( \frac{p_m}{\lambda^E \psi_m} \right)^\frac{\alpha_m}{\alpha_m-1} - 1 \right] + \frac{\psi_1}{\alpha_1}\left(\frac{p_1}{\lambda^E \psi_1} \right)^\frac{\alpha_1}{\alpha_1-1}.
\label{util_algo}
\end{align}

**Step 3**: If $\hat{U} < \bar{U}$, go to step 4. Else, if $\hat{U} \geq \bar{U}$, set $\frac{1}{\lambda_l^E}= \frac{\psi_{M+1}}{p_{M+1}}$ and $\frac{1}{\lambda_u^E}= \frac{\psi_{M}}{p_{M}}$. Go to step 5.

**Step 4**: Set $M=M+1$. If $M<K$, go to step 2. Else if $M=K$, set $\frac{1}{\lambda_l^E}= 0$ and $\frac{1}{\lambda_u^E}= \frac{\psi_{K}}{p_{K}}$. Go to step 5.

**Step 5**: Let $\hat{\lambda^E}= (\lambda_l^E+\lambda_u^E)/2$ and substitute $\hat{\lambda^E}$ into Equation (\ref{util_algo}) to obtain an estimate of $\hat{U}$. Go to step 6.

**Step 6**: If $|\lambda_l^E-\lambda_u^E| \leq \; tol_{\lambda}$ or $|\hat{U}-\bar{U}| \leq \; tol_{U}$, go to step 7. Else if $\hat{U}<\bar{U}$, update $\lambda^E_u= (\lambda_l^E+\lambda_u^E)/2$ and go to step 5. Else if $\hat{U}>\bar{U}$, update $\lambda^E_l= (\lambda_l^E+\lambda_u^E)/2$ and go to step 5.

**Step 7**: Compute the optimal Hicksian consumption levels for the first $I$ alternatives in the above descending order using Equation (\ref{foc13}). Set the remaining alternative consumption levels to zero and stop.
