---
title: "Multiple Discrete-Continuous Extreme Value Model Estimation and Simulation in R: The rmdcev Package"
author:
- affiliation: University of Saskatchewan
  name: Patrick Lloyd-Smith
date: "September 2019"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Put the title of your vignette here}
  %\VignetteEngine{knitr::rmarkdown}
  \usepackage[utf8]{inputenc}
fig_height: 6
fig_width: 4
fontfamily: mathpazo
fontsize: 12pt
geometry: margin=1in
header-includes:
- \usepackage{setspace}\singlespacing
- \usepackage{amsmath}
keywords: multiple discrete-continuous extreme value, Kuhn-Tucker, latent class, random
  parameters, demand estimation, welfare, preference heterogeneity, R
bibliography: biblio.bib
abstract: This paper introduces the package **rmdcev** in R for estimation and simulation
  of multiple-discrete continuous extreme value (MDCEV) models with individual heterogeneity.
  The models supported by **rmdcev** are the MDCEV model, the latent class MDCEV model,
  and the random parameters MDCEV model. The models are fit using maximum likelihood
  estimation or Bayesian estimation. The **rmdcev** package also implements demand
  forecasting and welfare calculation for policy simulation. The purpose of this paper
  is to describe the MDCEV estimation and simulation framework and to demonstrate
  all the functionalities of **rmdcev**.
---

```{r setup, include = TRUE, echo = FALSE, message = FALSE, warning = FALSE, eval = TRUE}
library(knitr)
hook_output = knit_hooks$get('output')
knit_hooks$set(output = function(x, options) {
  # this hook is used only when the linewidth option is not NULL
  if (!is.null(n <- options$linewidth)) {
    x = knitr:::split_lines(x)
    # any lines wider than n should be wrapped
    if (any(nchar(x) > n)) x = strwrap(x, width = n)
    x = paste(x, collapse = '\n')
  }
  hook_output(x, options)
})
# Load packages
library(dplyr)
library(rmdcev)
#knitr::opts_chunk$set(tidy.opts=list(width.cutoff=60),tidy=TRUE)
#opts_chunk$set(tidy.opts=list(width.cutoff=60),tidy=TRUE)
```


# Introduction

Individual choice contexts are often characterized by both extensive (i.e. what alternative to choose) and intensive (i.e. how much of an alternative to consume) margins (@bhatmultiple2008). These multiple discrete-continuous choice situations are pervasive, arising in transportation, marketing, health, and decisions regarding environmental resources (@bhatmultiple2014). The multiple-discrete continuous extreme value (MDCEV) demand model, also commonly called Kuhn-Tucker (KT) models in economics, is often employed to analyze these MDC situations and substantial progress has been made in improving these econometric modeling structures (@vonhaefenkuhn-tucker2005; @bhatmultiple2014). Despite the large potential applications for MDCEV models, there remains a gap between this potential and actual examples of these models being used. One of the reasons cited for the lack of widespread use of MDCEV models is that estimating and simulating these models is challenging. The explanations of methods used to work with these models are spread across many papers and few user friendly software tools are available. The purpose of this paper is to present a unified account for MDCEV estimation and simulation alongside computer code.

This paper presents an overview of the **R** [@r2008] package **rmdcev** which can estimate and simulate MDCEV models with discrete or continuous unobserved individual heterogeneity. Incoporating preference heterogeneity has been an important advancement in choice modeling. Unobserved preference heterogeneity can be accomodated assuming continuous distributions using random parameters or a latent class (LC) specification assuming a discrete distribution where people can be divided into distinct segments. Within each segment, the LC specification assumes preference homogeneity. The models in **rmdcev** can be fit using maximum likelihood estimation or Bayesian estimation. The **rmdcev** package also implements demand forecasting and welfare calculation for policy simulation. **rmdcev** is available from the Comprehensive R Archive Network (CRAN) at https://CRAN.R-project.org/package=rmdcev.

While there are several **R** packages available to estimate discrete choice data such as **mlogit** [@mlogit2019] and **gmnl** [@sarriasmultinomial2017]^[@sarriasmultinomial2017 provides a good overview of the different R packages available to estimate discrete choice models], there are less options for users interested in estimating and simulating MDCEV models. In addition to **rmdcev**, the [**apollo**](http://www.apollochoicemodelling.com/) package developed by Stephane Hess and David Palma at the Choice Modelling Centre in Leeds provides a flexible modelling platform for estimating MDCEV models and simulating demand behaviour [@hessapollo2019]. **apollo** estimates a full suite of choice models including discrete choice models and is thus more comprehensive then **rmdcev**. The main differences for MDCEV modeling between the two packages is that **rmdcev** 1) provides functions for calculating welfare implications of policy scenarios, 2) uses the Stan program [@carpenterstan2017] for Bayesian estimation and thus the user has access to specialized postestimation commands, and 3) is primarily coded in **C++** and thus around 20 times faster.

The paper first introduces the conceptual framework underlying MDCEV models and the connection to economic theory and welfare measures. Section [2](#models) also describes the various empirical specifications for MDCEV models. Section [3](#rmdcev) introduces the **rmdcev** package focusing first on estimation before moving on to discuss how to conduct welfare and demand simulations. Section [4](#conclusions) provides conclusions of the paper.

# Models {#models}

## Conceptual framework

This section describes the underlying conceptual framework for MDCEV models. Each individual $i$ maximizes utility through the choice of the numeraire or outside good ($x_{i1}$) and the non-numeraire alternatives ($x_{ik}$) subject to a monetary budget constraint. We assume there is a numeraire good (i.e. essential Hicksian composite good) which is always consumed and has a price of one. The individual's maximization problem is

\begin{equation}
\max_{x_{ik}, x_{i1}} U(x_{ik}, x_{i1}) \;\;\; s.t. \;\;\;y = \sum\limits^K_{k=2}p_{ik} x_{ik} + x_{i1}, \;\; x_{ik} \geq 0,\;\; k = 2,...,K  
\end{equation}

\noindent
where $x_{ik}$ is the consumption level for alternative $k$, $x_{i1}$ is consumption of the numeraire, $y$ is annual income, and $p_{ik}$ is the unit price of alternative $k$.

The resulting first-order KT conditions that implicitly define the solution to the optimal consumption bundles of $x_{ik}$ and $x_{i1}$ are

\begin{align}
\label{eq:kt_conditions}
\begin{split}
 \frac{U_{x_{ik}}}{U_{x_{i1}}} & \leq p_{ik},\; \; k = 1,....K , \\
  x_{ik}\left[\frac{U_{x_{ik}}}{U_{x_{i1}}} - p_{ik} \right] & = 0,\; \; k = 1,....K.
  \end{split}
\end{align}

For alternatives with positive consumption levels, the marginal rate of substitution between these alternatives and the numeraire good is equal to the price of the alternative. For unconsumed alternatives, the marginal rate of substitution between these alternatives and the numeraire good is less than the price of the alternatives. For the rest of the paper, we drop the subscript $i$ for notational simplicity.

These first-order conditions can be used to derive Marshallian and Hicksian demands and welfare measures. We assume that alternatives have non-price attribute $q_{k}$ and the vector of $k$ prices and attributes is denoted as $p$ and $q$. The Hicksian compensating surplus ($CS^H$) for a change in price and quality from baseline levels $p^0$ and $q^0$ to new 'policy' levels $p^1$ and $q^1$ is defined explicitly using an expenditure function

\begin{equation}
\label{eq:welfare}
CS^H = y - e(p^1, q^1, \bar{U}, \theta, \varepsilon)
\end{equation}

\noindent
where $\theta$ is the vector of structural parameters ($\psi_k, \alpha_k, \gamma_k$), $\varepsilon$ is a vector or matrix of unobserved heterogeneity, and $\bar{U} = V(p^0, q^0, y, \theta, \varepsilon)$ and represents baseline utility.


## Multiple discrete-continuous extreme value model (MDCEV)

The **rmdcev** package implements the random utility specification as introduced by @bhatmultiple2008. The model specifications included in **rmdcev** always assume an outside good (i.e. the numeraire good that is always consumed by every individual). The general utility function is specified as

\begin{equation}
U(x_k, x_1) = \sum_{k=2}^{K} \frac{\gamma_k}{\alpha_k}\psi_k \left[ \left( \frac{x_k}{\gamma_k} + 1 \right)^{\alpha_k} - 1 \right] + \frac{\psi_1}{\alpha_1}x_1^{\alpha_1} \label{utilkt}
\end{equation}

\noindent
where $\gamma_k > 0$, $\psi_k > 0$ and $\alpha_k \leq 1$ for all $k$ are required for this specification to be consistent with the properties of a utility function (@bhatmultiple2008). @bhatmultiple2008 provides a detailed overview of the parameter interpretation and in brief

- The $\psi_k$ parameters represent the marginal utility of consuming alternative $k$ at the point of zero consumption (i.e. baseline marginal utility).
- The $\gamma_k$ parameters are translation parameters that allow for corner solutions (i.e. zero consumption levels for alternatives) and also influence satiation. The lower the value of $\gamma_k$, the greater the satiation effect in consuming $x_k$.
- The $\alpha_k$ parameters control the rate of diminishing marginal utility of additional consumption. If $\alpha_k$ equal to one, then there is no satiation effects (i.e. constant marginal utility).

The 'random utility' element of the model is introduced into the baseline utility through a random error term as

\begin{equation}
\label{eq:psi}
\psi_k=\psi(z_k,\varepsilon_k)= exp(\beta'z_k+\varepsilon_k)
\end{equation}

\noindent
where $z_k$ is a set of variables that can include alternative-specific attributes and individual-specific characteristics, and $\varepsilon_k$ is an error term that allows for the utility function to be random over the population. We assume an extreme value distribution that is independently distributed across alternatives for $\varepsilon_k$ with an associated scale parameter of $\sigma$. For identification, we specify $\psi_1= e^{\varepsilon_1}$.

To ensure the estimated utility function corresponds to economic theory we specify $\gamma_k = exp(\gamma_k)$ such that $\gamma_k > 0$ and $\alpha_k = exp(\alpha_k)/(1 + exp(\alpha_k))$ such that $0 < \alpha_k < 1$. Weak complementarity, which is required for deriving unique welfare measures (@malerenvironment1974), is imposed in this specification by adding and subtracting one in the non-numeraire part of the utility function.

While the most general form of the MDCEV model includes $\psi_k$, $\gamma_k$, and $\alpha_k$ parameters for each alternative, Bhat (2008) discusses the identification concerns regarding estimating separate $\gamma_k$ and $\alpha_k$ parameters for each non-numeraire alternative. Typically only a subset of these parameters can be identified and there are three common utility function specifications:

1. $\alpha$-profile: set all $\gamma_k$ parameters to 1.

\begin{equation}
\label{eq:alpha}
U(x_k, x_1) = \sum_{k=2}^{K} \frac{1}{\alpha_k}exp(\beta'z_k+\varepsilon_k) \left[ \left( x_k + 1 \right)^{\alpha_k} - 1 \right] + \frac{exp(\varepsilon_1)}{\alpha_1}x_1^{\alpha_1}
\end{equation}

2. $\gamma$-profile: set all non-numeraire $\alpha_k$ parameters to 0.

\begin{equation}
\label{eq:gamma}
U(x_k, x_1) = \sum_{k=2}^{K} \gamma_k exp(\beta'z_k+\varepsilon_k) \ln\left( \frac{x_k}{\gamma_k} + 1 \right) + \frac{exp(\varepsilon_1)}{\alpha_1}x_1^{\alpha_1}
\end{equation}

3. hybrid-profile: set all $\alpha_k=\alpha_1=\alpha$.

\begin{equation}
\label{eq:hybrid}
U(x_k, x_1) = \sum_{k=2}^{K} \frac{\gamma_k}{\alpha} exp(\beta'z_k+\varepsilon_k) \left[ \left( \frac{x_k}{\gamma_k} + 1 \right)^{\alpha} - 1 \right] + \frac{exp(\varepsilon_1)}{\alpha}x_1^{\alpha}
\end{equation}

The likelihood function representing the model probability of the consumption pattern where $M$ alternatives are chosen can be expressed as @bhatmultiple2008

\begin{equation}
\label{eq:ll_base}
P(x^{*}_1,x^{*}_2...x^{*}_M,0,...,0) = \frac{1}{\sigma^{M-1}} \left(\prod_{m=1}^M c_m \right)\left(\sum_{m=1}^M \frac{p_m}{c_m} \right) \left( \ \frac{\prod_{m=1}^M e^{V_m/\sigma}}{ \left( \sum_{k=1}^J e^{V_k/\sigma} \right)^M }\right)(M-1)!
\end{equation}

\noindent
where $\sigma$ is the scale parameter and $c_m = \frac{1-\alpha_m}{x_m+ \gamma_m}$. The $V$ expression depend on what model specification is used:

1. $\alpha$-profle: $V_k = \beta' z_k + (\alpha_k-1)\ln\left( x_k + 1 \right) - \ln \left(p_k\right)$ for $k \geq 2$, and $V_1 = (\alpha_1-1)\ln(x_1)$.

2. $\gamma$-profle: $V_k = \beta' z_k - \ln\left( \frac{x_k}{\gamma_k} + 1 \right) - \ln \left(p_k\right)$ for $k \geq 2$, and $V_1 = (\alpha_1-1)\ln(x_1)$.

3. hybrid-profile: $V_k = \beta' z_k + (\alpha-1)\ln\left( \frac{x_k}{\gamma_k} + 1 \right) - \ln \left(p_k\right)$ for $k \geq 2$, and $V_1 = (\alpha-1)\ln(x_1)$.

In these specifications, the parameters ($\beta, \alpha_k , \gamma_k, \sigma$) are structural parameters that are assumed to be equal across the population which simplifies estimation. However, this fixed MDCEV specification is quite restrictive as it imposes that all individuals have the same tastes for altenatives (i.e. preference homeogeneity). This assumption is relaxed in the next two specifications.


## Latent class (LC-MDCEV) models

The latent class version of the MDCEV assumes that an individual belongs to a finite mixture of $S$ segments each indexed by $s$ ($s=1,2,...S$) [@sobhanilatent2013; @kuriyamalatent2010]. We do not observe which segment an individual belongs to but we can attribute a probability $\pi_{is}$ that individual $i$ is a member of segment $s$. We impose that $0 \leq \pi_{is} \leq 1$ and $\sum^S_{s=1} \pi_{is} = 1$ through the use of the logit link function as

\begin{equation}
\pi_{is} = \frac{exp(\delta_s'w_i)}{\sum^S_{s=1}exp(\delta_s'w_i)}
\end{equation}

\noindent
where $w_i$ is a vector of individual characteristics and $\delta_s$ is a vector of coefficients to be estimated. The $\delta_s$ coefficients determine how the individual characteristics affect the membership of individual $i$ in segment $s$. For identification, the $\delta_1$ coefficients for the first segment are set to zero.

The likelihood function can be written as

\begin{equation}
P = \prod_{i} \pi_{is}P_{is}
\end{equation}

where $P_{is}$ has the same form as Equation (\ref{eq:ll_base}) but is now class specific.

## Random parameters (RP-MDCEV) models

The random parameter specification of the MDCEV model assumes that the structural parameters $\theta =  (\beta, \alpha_k , \gamma_k)$ are not neccesarily fixed but have an assumed distribution [@bhatmultiple2008]. In **rmdcev**, parameters are distributed multivariate normal with a mean $\bar{\theta}$ and variance covariance matrix $\sum_{\theta}$ [@vonhaefenkuhn-tucker2005]. This structure allows for continuous preference heterogeneity and accomodates more fleixlbe correlation patterns between alternatives in a simlar fashion to the mixed logit model in discrete choice models. The $\sigma$ scale parameter is always assumed to be a fixed parameter.

The most flexible model specification is to estimate the full variance covariance matrix and if there are $Q$ parameters in $\theta$ then there are $Q(Q+1)/2$ unique variance covariance parameters to estimate in the correlated RP-MDCEV specification. An alternative is to assume the off-diagonal parameters are zero and estimate uncorrelated random parameters by estimating the $Q$ diagonal elements of $\sum_{\theta}$. If all elements of $\sum_{\theta}$ are assumed to be zero, the model collapses to the fixed MDCEV structure.

## A note on Bayesian versus classical maximum likelihood estimation

The MDCEV model without unobserved heterogeneity can be estimated using Bayesian or classical maximum likelihood techniques. The LC-MDCEV model can only be estimated using classical maximum likelihood techniques as Bayesian approaches are challenged by the 'label switching' problem. The RP-MDCEV models can only be estimated using Bayesian techniques as random parameter models require simulated maximum likelihood estimators and these are not implemented in **rmdcev** at this time.

While there are philosphical differences between Bayesian and classical maximum likelihood techniques to estimating models, the Bernstein-von Mises theorem suggests that the Bayesian posterior distribution are asymptotically equivalent to maximum likelihood estimates if the data generating process has been correctly specified [@traindiscrete2003].

# The rmdcev package {#rmdcev}

## Data format

The **rmdcev** uses **mdcev.data** function for handling multiple discrete-continuous data while ensuring the data is in the correct format and is suitable for estimation. The **rmdcev** package accepts data in "long" format (i.e. one row per available non-numeraire alternative for each individual). There is no row for the numeraire good. If there are $I$ individuals and $J$ non-numeraire alternatives, then the data frame should have $IxJ$ rows.

To illustrate the data, we can load the recreation data included with the **rmdcev** package. This data is from the Canadian Nature Survey and includes choices for number of days spent recreating in 17 different outdoor activities for 2,000 people [@federal20122014].

```{r, echo=T, data}
data(data_rec, package = "rmdcev")
```

Each recreation activity is characterized by the daily costs of participation for each individual. In additional to the recreation behaviour and prices, the data includes information on three individual characteristics: university (a dummy variable if the person has completed a university degree), ageindex (a person's age divided by the average age in sample), and urban (a dummy variable if a person lives in an urban area). Additional details on the data and price construction are provided in @lloydsmitheconomics2019. We can summarize the average consumption and price levels for each alternative as:

```{r, echo=T, summary}
data_rec %>%
	group_by(alt) %>%
	summarise(mean_quant = mean(quant),
			      mean_price = mean(price))
```

The data can be transformed into the structure for MDCEV estimation using the **mdcev.data** function:

```{r, echo=T, mdcev.data_test}
data_mdcev <- mdcev.data(data_rec,
					   id.var = "id",
					   alt.var = "alt",
					   choice = "quant")
```

The **id.var** argument indicates what varible uniquely identifies individuals in the data set, **alt.var** indicates the variable containing the variable that identifies the non-numeraire alternatives, and **choice** indicates the level of consumption made by the individuals. Two other optional arguments of **mdcev.data** are **price** and **income** indicating the individual-specific price levels for each alternative, and the income level for each individual. These two arguments only need to be explicitly specified if they are not labelled price and income. Additional variables containing information for alternative-specific attributes and individual characteristics can also be included. Data must be arranged by id and then alternative. 

The **mdcev.data** function also checks to ensure the data has the necessary variables, and that all individuals spend positive amounts on the numeraire good. If an individual does not have positive expenditures on the numeraire good, an error message is given.


## MDCEV estimation

###	A general overview of mdcev

All the various MDCEV model specifications are estimated using the **mdcev** function.

```{r, echo=T, mdcev}
args(mdcev)
```

The main arguments are briefly explained below:

- **formula**: Formula for the model to be estimated. The formula is divided in two parts, separated by the symbol **|}. The first part is reserved for the $z_k$ variables in $\psi$ as in Equation (\ref{eq:psi}). These can include alternative-specific and individual-specific variables. Interaction terms between variables can be included using the normal **formula** syntax of **z1:z2}. This is particularly useful for creating interaction terms to incorporate observed preference heterogeneity for alternative-specific variables and individual-specific characteristics. The second part corresponds for individual-specific characteristics that enter in the probability assignment in models with latent classes. This formula is based on the R package **formula** [@zeileisextended2010]. The formula will automatically include a constant but a constant can be omitted if -1 is used in the formula.

```{r, echo=T, formula}
formula = ~ z1 + z2 + z3
```

- **data** The ($IxJ$) data to be used in estimation as described above.

- **weights** An optional vector of sampling or frequency weights.

- **model** A string indicating which model specification to estimate. The four options are presented below:
	+ "alpha": $\alpha$-profile with all $\gamma_k$ parameters fixed equal to 1 (Equation (\ref{eq:alpha})).
	+ "gamma": $\gamma$-profile with one estimated $\alpha_1$ and all non-numeraire $\alpha_k$ parameters equal to 0 (Equation (\ref{eq:gamma})).
	+ "hybrid": hybrid-profile with a single estimated $\alpha$ parameter (i.e. $\alpha_1 = \alpha_k = \alpha$) (Equation (\ref{eq:hybrid})).
	+ "hybrid0": hybrid-profile with all $\alpha$ parameters fixed equal to 1e-3 (Equation (\ref{eq:hybrid})).

- **n_classes** The number of latent classes. Note that the LC model is automatically estimated as long as the prespecified number of classes is set greater than 1.

- **fixed_scale1** Whether to fix the scale parameter at 1.

- **trunc_data** Whether the estimation should be adjusted for truncation. This option should be used if data was only collected from people that consume at least one non-numeraire alternative. For example, if a intercept survey collected recreation data at a park then people that did not visit the park are not included in the data.

- **seed** Random seed.

- **algorithm** Either "Bayes" for Bayesian estimation or "MLE" for maximum likelihood estimation. The MLE algorithm uses the Limited-memory BFGS which approximates the Broyden–Fletcher–Goldfarb–Shanno (BFGS) algorithm but uses less computer memory.

- **flat_priors** indicator if completely uninformative priors should be specified. If using MLE, the optimizing function will then be equal to log-likelihood. Defaults to 1 if MLE used and 0 if Bayes used.

- **print_iterations** Whether to print itermediate iteration information or not.

- **std_errors** Compute standard errors using the delta method ("deltamethod") or multivariate normal draws ("mvn").

- **n_draws** The number of multivariate normal draws for standard error calculations. Default is 50.

- **initial.parameters** Specify initial parameters instead of starting at random.

### Estimating MDCEV using maximum likelihood techniques

We estimate a MDCEV model using the **Recreation** data where we include activity-specific constants in $\psi$. We exclude the constant by including **-1** as below.

```{r, echo=T, set_data}
data_model <- mdcev.data(data_rec, subset = id < 201,
					   id.var = "id",
					   alt.var = "alt",
					   choice = "quant")  

formula <- ~ alt - 1

```

We specify the hybrid model specification where a single $\alpha$ is estimated for the numeraire and non-numeraire alternatives by setting **model = "hybrid"}. We use maximum likelihood estimation by setting **algorithm = "MLE"}. Standard errors can be calculated using the delta method using the **std_errors** option as shown below. For these examples we are going to use a subset of 200 individuals from the data.

The syntax for the model is the following:

```{r, echo=T, estimation_mdcev_hybrid}
mdcev_mle <- mdcev(formula,
                  data = data_model,
                  model = "hybrid",
                  algorithm = "MLE",
                  std_errors = "deltamethod",
                  print_iterations = FALSE)
```

Setting **print_iterations = TRUE** will print out intermediate iteration results as the model converges.

The output of the function can be accessed by calling summary.

```{r, echo=T,summary_mdcev_hybrid}
summary(mdcev_mle)
```

The summary includes overall model and estimation information and the parameter estimates.

In the next example, we estimate the $\alpha$-profile of the utility function by changing the model argument to **"alpha"}.

```{r, estimation_mdcev_alpha, message = FALSE, warning = FALSE}
mdcev_mle <- mdcev(formula,
                    data = data_model,
                    model = "alpha",
                    algorithm = "MLE",
				  	std_error = "deltamethod",
                    print_iterations = FALSE)
```

```{r, echo=T, echo=T,summary_mdcev_alpha}
summary(mdcev_mle)
```

The parameter estimates are quite different from the previous model as all the non-numeraire $\gamma$ parameters are fixed at 1 and alternative-specific $\alpha_k$ parameters are estimated.

The $\gamma$-profile version of the model can be estimated by changing the model to **"gamma"** as the next example demonstrates.

```{r, estimation_mdcev_les, message = FALSE, warning = FALSE}
mdcev_mle <- mdcev(formula,
                    data = data_model,
                    model = "gamma",
                    algorithm = "MLE",
				  	std_error = "deltamethod",
                    print_iterations = FALSE)
```

```{r,  echo=T,summary_mdcev_les}
summary(mdcev_mle)
```

The same number of parameters are estimated in all three models and the log-likelihood is highest for the $\gamma$-profile specification.

### Estimating MDCEV using Bayesian techniques

The exact same models can be fit using Bayesian estimation by changing the algorithm call to **"Bayes"}. Bayesian estimation is implemented using the Stan programming language [@carpenterstan2017]. The Bayesian framework requires careful choice of priors for the parameters. All priors are assumed to follow a normal distribution with a fixed mean and the user can change the standard deviation through these options in the mdcev function.

- **prior_psi_sd** standard deviation for normal prior with mean 0.
- **prior_gamma_sd** standard deviation for normal prior with mean 0.
- **prior_alpha_sd** standard deviation for normal prior with mean 0.5.
- **prior_scale_sd** standard deviation for normal prior with mean 1.

There are also a number of further options for Bayesian estimation. For example, the number of iterations (n_iterations), number of chains (n_chains), and number of cores (n_cores) for parallel implementation of the chains can also be chosen. The full set of options for Bayesian estimation are presented below.

- **random_parameters** The form of the covariance matrix for the parameters. Options are
	+ 'fixed' for no random parameters,
	+ 'uncorr for uncorrelated random parameters, and
	+ 'corr' for correlated random parameters.

- **n_iterations** The number of iterations in Bayesian estimation.

- **n_chains** The number of chains in Bayesian estimation.

- **n_cores** The number of cores to use in Bayesian estimation. Can set using options(mc.cores = parallel::detectCores()).

- **max_tree_depth** http://mc-stan.org/misc/warnings.html#maximum-treedepth-exceeded

- **adapt_delta** http://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup

- **lkj_shape_prior** Prior for Cholesky matrix for correlated random parameters

In this example, we estimate the hybrid0 specification using Bayesian techniques. We set the number of iterations to 200 and use 4 independent chains.

```{r,eval=T, echo=T, estimation_mdcev_bayes, message = FALSE, warning = FALSE}
mdcev_bayes <- mdcev(formula,
                        data = data_model,
                        model = "hybrid0",
                        algorithm = "Bayes",
                        n_iterations = 200,
                        n_chains = 4,
                        print_iterations = FALSE)
```

The output of the function can be accessed by calling summary.

```{r,eval=T, echo=T, summary_mdcev_bayes}
	summary(mdcev_bayes)
```


One benefit of using the Bayesian approach is that we can take advantage of the postestimation commands, interactive diagnostics, and posterior analysis in **rstan**, [**bayesplot**](https://mc-stan.org/bayesplot/) [@gabrybayesplot2019], and [**shinystan**](http://mc-stan.org/shinystan/) [@muthuser2018]. For example, the effective sample size reports the estimated number of independent draws from the posterior distribution for each parameter [@stan2019]. The interested reader is refered to these packages for additional details.

### Estimating LC-MDCEV models

In this example, we estimate a LC-MDCEV model using the **Recreation** data. We set the number of classes equal to 2 and we use data on 500 individuals. We would like to include the **university**, **ageindex**, and **urban** in the membership equation and we include them in the **formula** interface. Note that we need to include at least a constant in the formula. The LC model is automatically estimated as long as the prespecified number of classes (**n_classes}) is set greater than 1.

```{r, estimation_mdcev_lc, message = FALSE, warning = FALSE}

data_model <- mdcev.data(data_rec, subset = id < 501,
					   id.var = "id",
					   alt.var = "alt",
					   choice = "quant")  

formula <- ~ alt - 1 | university + ageindex + urban

mdcev_lc <- mdcev(formula,
                  data = data_model,
                  n_classes = 2,
                  model = "hybrid0",
                  algorithm = "MLE",
                  print_iterations = FALSE)
```

```{r, summary_mdcev_lc}
summary(mdcev_lc)
```

In this LC example, we assume that there are two types of people that have different preferences for recreation. The probability of class assignment depends on unobserved factors and the three sociodemographic factors included in the membership equation. The summary output reports the average class probabiliies as being 32% for class 1 and 68% for class 2. The $\psi$ parameters across classes are similar although there are some noticable differences. The $\gamma$ parameters, on the other hand, show that satiation between classes is quite different between the classes. To assist speed and convergence issues, **rmdcev** uses the results of the MDCEV model as starting values when estimating the LC-MDCEV model. The MDCEV model output can be accessed from **mdcev_lc[["mdcev_fit"]]** object for comparison.

### Estimating RP-MDCEV models

Random parameter models require defining and parameterizing the variance covariance matrix. For uncorrelated random parameters, the diagonal elements of the variance covariance matrix are estimated and the off-diagonal elements are assumed to be zero. For correlated random parameters, the variance covariance matrix is fully estimated and can be parameterized in many ways. The **rmdcev** package defines the variance covariance matrix in terms of Cholesky factors of the correlation matrix and a vector of standard deviations for numerical stability. Thus the variance covariance matrix is specified as

\begin{equation}
\sum = diag(\tau) \; x \; LL^T \; x \; diag(\tau)
\end{equation}

where $\tau$ is a vector of standard deviations, and $L$ is the cholesky factors of the correlation matrix.

In this example, we estimate an uncorrelated random parameters MDCEV model using **rmdcev**. We set the argument **random_parameters = "uncorr"** to indicate that uncorrelated random parameters will be estimated. All random parameters follow a normal distribution. We change the **formula** specification to only include a single constant term for all non-numeraire alternatives. The scale parameter is fixed at 1 using **fixed_scale1 = 1}.

```{r,eval=T, echo=T, estimation_mdcev_rp, message = FALSE, warning = FALSE}
data_model <- mdcev.data(data_rec, subset = id < 201,
					   id.var = "id",
					   alt.var = "alt",
					   choice = "quant") 

mdcev_rp <- mdcev(formula = ~ 1,
					data = data_model,
					model = "hybrid0",
					algorithm = "Bayes",
					n_chains = 4,
					fixed_scale1 = 1,
					n_iterations = 200,
					random_parameters = "uncorr",
					print_iterations = FALSE)
```


```{r, eval=T, summary_mdcev_rp}
summary(mdcev_rp)
```

The results show the means of the random parameters followed by the estimated standard deviations. The standard deviations that are estimated to be different from zero suggest there is heterogeneity in preference parameters. The correlated random parameters specification can be estimated by setting **random_parameters = "corr"}.

## Simulating MDCEV demand and welfare scenarios

The **rmdcev** package includes simulation functions for calculating welfare measures and forecasting demand under alternative policy scenaros. The overall approach used for simulation is first introduced and then code examples are given.

### Overview of simulation steps

Once the model parameters are estimated, there are two steps to simulation in MDCEV models. In the first step we draw simulated values for the unobserved heterogeneity term ($\varepsilon$) using Monte Carlo techniques. The second step uses these error draws, the previously estimated model parameters, and the underlying data to calculate Marshallian demands for forecasting or Hicksian demands for welfare analysis. These two steps are described below.

**Step 1: simulating unobervered heterogeneity**

Monte Carlo simulation techniques can be employed to draw simulated values of the unobserved heterogeneity ($\varepsilon$) using either unconditional or conditional draws.

1. Unconditional error draws: draw from the entire distribution of unobserved heterogeneity using the following formula

\begin{equation}
\varepsilon_{k} = -log(-log(draw(0,1))) * \sigma
\end{equation}

where $draw(0,1)$ is a draw between 0 and 1 and $\sigma$ is the scale parameter. **rmdcev** allows errors to be drawn using uniform draws or the Modified Latin Hypercube Sampling algorithm (@hesson2006).

2. Conditional error draws: draw errors terms to reflect behaviour and dependent on whether alternative is consumed or not [@vonhaefenincorporating2003; @vonhaefenestimation2004]:

- If $x_k>0$, set  $\varepsilon_k = (V_1 - V_k)/ \sigma$ where $V_1$ and $V_k$ depend on the model specification as detailed above.
- If $x_k=0$, $\varepsilon_k < (V_1 - V_k)/ \sigma$ and simulate $\varepsilon_k$ from the truncated type I extreme value distribution such that

\begin{equation}
\varepsilon_k = -log(-log(draw(0, 1) * exp(-exp(\frac{V_1 - V_k}{\sigma})))) * \sigma
\end{equation}

In the conditional error draw approach, we normalize $\varepsilon_1=0$.

The main differences between these two error draw approaches is that in the conditional approach, we draw errors such that the model perfectly predicts the observed consumption patterns in the baseline state [@vonhaefenkuhn-tucker2005]. Thus the conditional approach uses observed behaviour by individuals to characterize unobserved heterogeneity. If the model correctly specifies the data generating process, the sample means of the conditional and unconditional approaches should converge in expectation. Another difference between the two approaches is that the unconditional approach uses more computation time. The reason for the relative slowness of the unconditional approach is the need to calculate consumption patterns in the baseline state as well as simulate the entire distribution of unobserved heterogeneity.

**Step 2: Calculating welfare measures and demand forecasts**

With the error draws in hand, the second step is to simulate demand or welfare changes. Compared to welfare measures in discrete choice models, welfare calculation in MDCEV models is more challenging because of the two Kuhn-Tucker conditions in Equation (\ref{eq:kt_conditions}). For a given policy scenario, a priori, we do not know which alternatives have a positive or zero consumption level. **rmdcev** implements the @pinjaricomputationally2011 efficient demand forecasting routine for simulating demand behaviour which relies on calculting Marshallian demands. For welfare calculations, we need to calculate the expenditure function in Equation (\ref{eq:welfare}) which relies on Hicksian demands. These are calculated using the approach described by @lloydsmithnew2018. The demand and welfare simulation approaches share a lot of commonalities and thus only the approach used for welfare calculations are fully described in the appendix. The specific steps for demand simulation is explained in-depth in @pinjaricomputationally2011 and the interested reader is encouraged to read Section 4 of the paper for the exact details.

### Welfare analysis

In **rmdcev**, the functions for welfare and demand simulation have been divided into 3 steps to allow users to parallelize operations as desired.

##### 1. Define policy scenarios

In the first step, we define the number of alternative policy scenarios to use in simulation and then specify changes to the $\psi$ variables and prices of alternatives. The CreateBlankPolicies function has been created to easily set-up the required lists for the simulation. These policies can then be manually edited according to the specific policy scenario. For prices, **rmdcev** is set up to accept additive changes in prices that impact all individuals the same. For the $\psi$ variable changes, the package is set up to accept any new values for these variables. Depending on the number of individuals and number of policies, the generated policies list can be quite large. If the user is only interested in assessing price changes, then you can use **price_change_only = TRUE** which ensures duplicate $\psi$ data is not created.

In this example, we are interested in two separate policies. The first policy increases the costs of all recreation activities by \$1 and the second policy increases the cost of all four hunting activities by \$10. The policy set-up for these two scenarios is demonstrated below.

```{r, sim_mdcev_welfare_policy}
nalts <- mdcev_mle$stan_data[["J"]]
npols <- 2

policies<-  CreateBlankPolicies(npols = npols,
								nalts = nalts,
								mdcev_mle$stan_data[["dat_psi"]],
								price_change_only = TRUE)

policies$price_p[[1]] <- c(0, rep(1, nalts))
policies$price_p[[2]][10:13] <- rep(10, 4)
```

For policy scenarios that involve changes in the $\psi$ variables, the user can change the **dat_psi** list of the **policies** object. For example, the following code will increase the value of the third variable by 20\% in policy scenario 1.

```{r, sim_mdcev_welfare_policy_psi}

policies$dat_psi[[1]][3] <- policies$dat_psi[[1]][3]*1.2
```

##### 2. Prepare simulation data

The second step is to combine the parameter estimates, data, and policy scenarios into a data format for simulation. The PrepareSimulationData function uses the model fit and the user defined policy scenarios to create this specific data format. This function separates the output into individual-specific data (df_indiv), data common to all individuals (df_common), and simulation options (sim_options).

```{r, sim_mdcev_welfare_prepare}
df_sim <- PrepareSimulationData(mdcev_mle, policies)
```

##### 3. Simulate MDCEV model

The third step is to simulate the policy scenario using the formatted data and the **mdcev.sim** function. The specific steps for the simulation algorithms are described in Appendix A. The user chooses the type of error draws (unconditional or conditional as described above), the number of error draws, and whether to simulate the demand or welfare changes. Note that the first time **mdcev.sim** is run in each session, the **C++** simulation code is compiled. Subsequent function calls do not require the code to be recompiled.


```{r, eval=T, sim_mdcev_welfare}
welfare <- mdcev.sim(df_sim$df_indiv,
					 df_common = df_sim$df_common,
					 sim_options = df_sim$sim_options,
					 cond_err = 1,
					 nerrs = 15,
					 sim_type = "welfare")
summary(welfare)
```

The output of the **mdcev.sim** for welfare analysis is an object of class **mdcev.sim** which contains a list of matrices where each element of the list is for an individual and the matrix consists of rows for each policy scenario and columns for each parameter simulation.

The summary function computes summary statistics across all individuals. For example, the average welfare change for a \$1 daily increase in all recreation costs is -\$129.

The reason these last two steps are separate is to allow users to parallelize the simulation step as the last step can be computationally intensive. The number of simulations is a multiplicative function of the number of individuals, number of policies, number of parameter estimate simulations, and the number of error draws ($I$ x $npols$ x $nsims$ x $nerrs$). Even for modestly sized data, the total number of simulations can easily reach well into the millions or billions. All simulations are conducted at the individual level which allows the user to easily parallelize the mdcev.sim function using the **parallel** package or similar packages.

### Demand forecasting

This section demonstrates the demand forecasting capabilities of **rmdcev**. Please refer to the previous section for an overview of the three steps to simulation.

```{r, eval=T, sim_mdcev_demand}
policies <-	CreateBlankPolicies(npols = 2,
								nalts = mdcev_mle$stan_data[["J"]],
								mdcev_mle$stan_data[["dat_psi"]],
								price_change_only = TRUE)

policies$price_p[[1]] <- c(0, rep(1, nalts))
policies$price_p[[2]][10:13] <- rep(10, 4)
df_sim <- PrepareSimulationData(mdcev_mle, policies)

demand <- mdcev.sim(df_sim$df_indiv,
						df_common = df_sim$df_common,
						sim_options = df_sim$sim_options,
					 	cond_err = 1,
						nerrs = 20,
						sim_type = "demand")
summary(demand)

```

The output of the demand simulation a **mdcev.sim** object with a list of $I$ elements, one for each individual. Within each element there are nsim lists each containing a matrix of demands. The rows of the matrix are for each policy scenario and the columns represent each alternative. The summary function computes summary statistics.

## Creating simulated MDCEV data

Simulated MDCEV data can be easily created for model assessment and Monte Carlo analysis. To demonstrate this functionality of **rmdcev**, we can generate some simulated data for 1,000 individuals with 10 non-numeraire alternatives and the following parameter values.

```{r, eval=T, fake_simulate}
model <- "hybrid"
nobs <- 1000
nalts <- 10
sim.data <- GenerateMDCEVData(model = model,
								nobs = nobs,
								nalts = nalts,
								alpha_parms = 0.5,
								scale_parms = 1,
								gamma_parms = stats::runif(nalts, 1, 2),
								psi_i_parms = c(-1.5, 3, -2, 1, 2),
								psi_j_parms = c(-5, 0.5, 2))
```

Next, we estimate the MDCEV model using maximum likelihood techniques to recover the parameter estimates.

```{r, fake_estimate, message = FALSE, warning = FALSE}
mdcev_mle <- mdcev(formula = ~ b1 + b2 + b3 + b4 + b5 + b6 + b7 + b8 - 1,
        				   data = sim.data$data,
        				   model = model,
        				   algorithm = "MLE",
        				   print_iterations = FALSE)
```

We can compare the estimated parameters from the model with the true values. As shown below, the model is successful at recovering the parameters for the simulated data.

```{r, eval=T, fake_compare}
parms_true <- tbl_df(sim.data$parms_true) %>%
	mutate(true = as.numeric(true))

output <- tbl_df(mdcev_mle[["stan_fit"]][["theta_tilde"]]) %>%
				dplyr::select(-tidyselect::starts_with("log_like"),         
							  -tidyselect::starts_with("sum_log_lik"))

names(output)[1:mdcev_mle$parms_info$n_vars$n_parms_total] <- mdcev_mle[["parms_info"]][["parm_names"]][["all_names"]]

output<- output %>%
		tibble::rowid_to_column("sim_id") %>%
		tidyr::gather(parms, value, -sim_id)

coefs <- output %>%
	mutate(parms = gsub("\\[|\\]", "", parms)) %>%
	group_by(parms) %>%
	summarise(mean = mean(value),
			  sd = sd(value),
			  zstat = mean / sd,
			  cl_lo = quantile(value, 0.025),
			  cl_hi = quantile(value, 0.975)) %>%
	left_join(parms_true, by = "parms") %>%
	print(n=200)
```

# Conclusions {#conclusions}

The **rmdcev** package implements the multiple discrete-continuous extreme value model with heterogeneity that can be continuous (i.e. random parameters) or discrete (i.e. latent classes). Models can be estimated using maximum likelihood or Bayesian techniques. This paper demonstrates the use of the pacakage to estimate several model specifications and to derive demand forecasts and welfare implications of policy scenarios. To my knowledge, there is no other available statistical package that can estimate welfare implications of policy scenarios using MDCEV models. I hope that the publication of **rmdcev** will make MDCEV modeling available to a wider audience.

# Appendix A: Specific steps for simulating MDCEV models {-}

There are two alogrithms that differ depending on the MDCEV model specification. If a single $\alpha$ parameter is estimated (i.e. model = "hybrid" or "hybrid0"), then we can use the hybrid approach to welfare simulation. If there are heterogenous $\alpha$ parameters, then we can use the general approach to welfare simulation. The hybrid approach is less computationally intensive and provides an exact analytical solution but the general approach can be used with all utility specifications. The specific steps for both algorithms are described below. Additional details are provided in @lloydsmithnew2018.

**Steps in algorithm for hybrid-profile utility specifications**

	**Step 0**: Assume that only the numeraire alternative is chosen and let the number of chosen alternatives equal one (M=1).

**Step 1**: Using the data, model parameters, and either conditional or unconditional simulated error term draws, calculate the price-normalized baseline utility values ($\psi_k/p_k$) for all alternatives. Sort the $K$ alternatives in the descending order of their price-normalized baseline utility values. Note that the numeraire alternative is in the first place. Go to step 2.

**Step 2**: Compute the value of $\lambda^E$ using the following equation:

\begin{equation}
\frac{1}{\lambda^E} = \left[ \frac{\alpha \bar{U} + \sum_{m=2}^{M} \gamma_m \psi_m} {\sum_{m=2}^{M} \gamma_m \psi_m \left( \frac{p_m}{\psi_m} \right)^\frac{\alpha}{\alpha-1} + \psi_1 \left(\frac{p_1}{\psi_1} \right)^\frac{\alpha}{\alpha-1}} \right] ^\frac{\alpha-1}{\alpha}
\end{equation}

Go to step 3.

**Step 3**: If $\frac{1}{\lambda^E} > \frac{\psi_{M+1}}{p_{M+1}}$, go to step 4. Else if $\frac{1}{\lambda^E} < \frac{\psi_{M+1}}{p_{M+1}}$, set $M = M + 1$. If $M < K$, go back to step 2. If $M = K$, go to step 4.

**Step 4**: Compute the optimal Hicksian consumption levels for the first $I$ alternatives in the above descending order using the following equations

\begin{align}
\label{eq:optimal_x}
x_1 &=   \left( \frac{p_1}{\lambda^E \psi_1} \right)^\frac{1}{\alpha_1-1}\text{, and} \\
x_m &=   \left[ \left( \frac{p_m}{\lambda^E \psi_m} \right)^\frac{1}{\alpha_m-1}-1 \right]\gamma_m, \; \; \text{if} \; \; x_m > 0.
\end{align}

Set the remaining alternative consumption levels to zero and stop.

**Steps in algorithm for general utility specifications**

	In this context, there is no closed-form expressions for $\lambda^E$ and we need to conduct a numerical bisection routine. Let $\hat{\lambda^E}$ and $\hat{U}$ be estimates of $\lambda^E$ and $U$ and let $tol_{\lambda}$ and $tol_{U}$ be the tolerance levels for estimating $\lambda^E$ and $U$ that can be arbitrarily small. The algorithm works as follows:

	**Step 0**: Assume that only the numeraire is chosen and let the number of chosen alternatives equal one (M=1).

**Step 1**: Using the data, model parameters, and either conditional or unconditional simulated error term draws, calculate the price-normalized baseline utility values ($\psi_k/p_k$) for all alternatives. Sort the $K$ alternatives in the descending order of their price-normalized baseline utility values. Note that the numeraire is in the first place. Go to step 2.

**Step 2**: Let $\frac{1}{\hat{\lambda^E}} = \frac{\psi_{M+1}}{p_{M+1}}$ and substitute $\hat{\lambda^E}$ into the following quation to obtain an estimate of $\hat{U}$.

\begin{align}
\bar{U}=\sum_{M=2}^{M} \frac{\gamma_m}{\alpha_m}\psi_m \left[ \left( \frac{p_m}{\lambda^E \psi_m} \right)^\frac{\alpha_m}{\alpha_m-1} - 1 \right] + \frac{\psi_1}{\alpha_1}\left(\frac{p_1}{\lambda^E \psi_1} \right)^\frac{\alpha_1}{\alpha_1-1}.
\end{align}

**Step 3**: If $\hat{U} < \bar{U}$, go to step 4. Else, if $\hat{U} \geq \bar{U}$, set $\frac{1}{\lambda_l^E}= \frac{\psi_{M+1}}{p_{M+1}}$ and $\frac{1}{\lambda_u^E}= \frac{\psi_{M}}{p_{M}}$. Go to step 5.

**Step 4**: Set $M=M+1$. If $M<K$, go to step 2. Else if $M=K$, set $\frac{1}{\lambda_l^E}= 0$ and $\frac{1}{\lambda_u^E}= \frac{\psi_{K}}{p_{K}}$. Go to step 5.

**Step 5**: Let $\hat{\lambda^E}= (\lambda_l^E+\lambda_u^E)/2$ and substitute $\hat{\lambda^E}$ into the equation of step 2 to obtain an estimate of $\hat{U}$. Go to step 6.

**Step 6**: If $|\lambda_l^E-\lambda_u^E| \leq \; tol_{\lambda}$ or $|\hat{U}-\bar{U}| \leq \; tol_{U}$, go to step 7. Else if $\hat{U}<\bar{U}$, update $\lambda^E_u= (\lambda_l^E+\lambda_u^E)/2$ and go to step 5. Else if $\hat{U}>\bar{U}$, update $\lambda^E_l= (\lambda_l^E+\lambda_u^E)/2$ and go to step 5.

**Step 7**: Compute the optimal Hicksian consumption levels for the first $M$ alternatives in the above descending order using Equation (\ref{eq:optimal_x}). Set the remaining alternative consumption levels to zero and stop.

# References {-}
