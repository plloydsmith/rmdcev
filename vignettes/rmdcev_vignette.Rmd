---
title: "Multiple Discrete-Continuous Extreme Value Model Estimation and Simulation in R: The rmdcev Package"
author:
- affiliation: University of Saskatchewan
  name: Patrick Lloyd-Smith
date: "July 2019"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Put the title of your vignette here}
  %\VignetteEngine{knitr::rmarkdown}
  \usepackage[utf8]{inputenc}
fig_height: 6
fig_width: 4
fontfamily: mathpazo
fontsize: 12pt
geometry: margin=1in
header-includes:
- \usepackage{setspace}\singlespacing
- \usepackage{amsmath}
keywords: multiple discrete-continuous extreme value, Kuhn-Tucker, latent class, random
  parameters, demand estimation, welfare, preference heterogeneity, R
bibliography: biblio.bib
abstract: This paper introduces the package **rmdcev** in R for estimation and simulation
  of multiple-discrete continuous extreme value (MDCEV) models with individual heterogeneity.
  The models supported by **rmdcev** are the MDCEV model, the latent class MDCEV model,
  and the random parameters MDCEV model. The models are fit using maximum likelihood
  estimation or Bayesian estimation. The **rmdcev** package also implements demand
  forecasting and welfare calculation for policy simulation. The purpose of this paper
  is to describe the MDCEV estimation and simulation framework and to demonstrate
  all the functionalities of **rmdcev**.
---

```{r setup, include = TRUE, echo = FALSE, message = FALSE, warning = FALSE, eval = TRUE}
library(knitr)
hook_output = knit_hooks$get('output')
knit_hooks$set(output = function(x, options) {
  # this hook is used only when the linewidth option is not NULL
  if (!is.null(n <- options$linewidth)) {
    x = knitr:::split_lines(x)
    # any lines wider than n should be wrapped
    if (any(nchar(x) > n)) x = strwrap(x, width = n)
    x = paste(x, collapse = '\n')
  }
  hook_output(x, options)
})
# Load packages
library(dplyr)
library(rmdcev)
#knitr::opts_chunk$set(tidy.opts=list(width.cutoff=60),tidy=TRUE)
#opts_chunk$set(tidy.opts=list(width.cutoff=60),tidy=TRUE)
```


# Introduction

Individual choice contexts are often characterized by both extensive (i.e. what alternative to choose) and intensive (i.e. how much of an alternative to consume) margins (@bhatmultiple2008). These multiple discrete-continuous choice situations are pervasive, arising in transportation, marketing, health, and decisions regarding environmental resources (@bhatmultiple2014). The multiple-discrete continuous extreme value (MDCEV) demand model, also commonly called Kuhn-Tucker (KT) models in economics, is often employed to analyze these MDC situations and substantial progress has been made in improving these econometric modeling structures (@vonhaefenkuhn-tucker2005; @bhatmultiple2014). Despite the large potential applications for MDCEV models, there remains a gap between this potential and actual examples of these models being used. One of the reasons cited for the lack of widespread use of MDCEV models is that estimating and simulating these models is challenging. The explanations of methods used to work with these models are spread across many papers and few user friendly software tools are available. The purpose of this paper is to present a unified account for MDCEV estimation and simulation alongside computer code.

This paper presents an overview of the R [@r2008] package **rmdcev** which can estimate and simulate MDCEV models with discrete or continuous unobserved individual heterogeneity. Incoporating preference heterogeneity has been an important advancement in choice modeling. Unobserved preference heterogeneity can be accomodated assuming continuous distributions using random parameters or a latent class (LC) specification assuming a discrete distribution where people can be divided into distinct segments. Within each segment, the LC specification assumes preference homogeneity. The models in **rmdcev** can be fit using maximum likelihood estimation or Bayesian estimation. The **rmdcev** package also implements demand forecasting and welfare calculation for policy simulation. **rmdcev** is available from the Comprehensive R Archive Network (CRAN) at https://CRAN.R-project.org/package=rmdcev. 

In addition to **rmdcev**, the [**apollo**](http://www.apollochoicemodelling.com/) package developed by Stephane Hess and David Palma at the Choice Modelling Centre in Leeds provides a flexible modelling platform for estimating MDCEV models and simulating demand behaviour [@hessapollo2019]. **apollo** estimates a full suite of choice models including discrete choice models and is thus more comprehensive then **rmdcev**. The main differences for MDCEV modeling between the two packages is that **rmdcev** 1) provides functions for calculating welfare implications of policy scenarios, 2) uses the Stan program [@carpenterstan2017] for Bayesian estimation and thus the user has access to specialized postestimation commands, and 3) is primarily coded in C++ and thus around 20 times faster.

The paper first introduces the conceptual framework underlying MDCEV models and the connection to economic theory and welfare measures. Section [2](#models) also describes the various empirical specifications for MDCEV models. Section [3](#rmdcev) introduces the **rmdcev** package focusing first on estimation before moving on to discuss how to conduct welfare and demand simulations. Section [4](#conclusions) provides conclusions of the paper.

# Models {#models}

## Conceptual framework

This section describes the underlying conceptual framework for MDCEV models. Each individual $i$ maximizes utility through the choice of the numeraire good ($x_{i1}$) and the non-numeraire alternatives ($x_{ik}$) subject to a monetary budget constraint. We assume there is a numeraire good (i.e. essential Hicksian composite good) which is always consumed and has a price of one. The individual's maximization problem is

\begin{equation}
\max_{x_{ik}, x_{i1}} U(x_{ik}, x_{i1}) \;\;\; s.t. \;\;\;y = \sum\limits^K_{k=2}p_{ik} x_{ik} + x_{i1}, \;\; x_{ik} \geq 0,\;\; k = 2,...,K  
\end{equation}

\noindent
where $x_{ik}$ is the consumption level for alternative $k$, $x_{i1}$ is consumption of the numeraire, $y$ is annual income, and $p_{ik}$ is the unit price of alternative $k$.

The resulting first-order KT conditions that implicitly define the solution to the optimal consumption bundles of $x_{ik}$ and $x_{i1}$ are

\begin{align}
\label{eq:kt_conditions}
\begin{split}
 \frac{U_{x_{ik}}}{U_{x_{i1}}} & \leq p_{ik},\; \; k = 1,....K , \\
  x_{ik}\left[\frac{U_{x_{ik}}}{U_{x_{i1}}} - p_{ik} \right] & = 0,\; \; k = 1,....K.
  \end{split}
\end{align}

For alternatives with positive consumption levels, the marginal rate of substitution between these alternatives and the numeraire good is equal to the price of the alternative. For unconsumed alternatives, the marginal rate of substitution between these alternatives and the numeraire good is less than the price of the alternatives. For the rest of the paper, I drop the subscript $i$ for notational simplicity.

These first-order conditions can be used to derive Marshallian and Hicksian demands and welfare measures. We assume that alternatives have non-price attribute $q_{k}$ and the vector of $k$ prices and attributes is denoted as $p$ and $q$. The Hicksian compensating surplus ($CS^H$) for a change in price and quality from baseline levels $p^0$ and $q^0$ to new 'policy' levels $p^1$ and $q^1$ is defined explicitly using an expenditure function

\begin{equation}
\label{eq:welfare}
CS^H = y - e(p^1, q^1, \bar{U}, \theta, \varepsilon)
\end{equation}

\noindent
where $\theta$ is the vector of structural parameters ($\psi_k, \alpha_k, \gamma_k$), $\varepsilon$ is a vector or matrix of unobserved heterogeneity, and $\bar{U} = V(p^0, q^0, y, \theta, \varepsilon)$ and represents baseline utility.


## Multiple discrete-continuous extreme value model (MDCEV)

The **rmdcev** package implements the random utility specification as introduced by @bhatmultiple2008. The model specifications included in **rmdcev** always assume an outside good (i.e. a good that is always consumed by every individual). The general utility function is specified as

\begin{equation}
U(x_k, x_1) = \sum_{k=2}^{K} \frac{\gamma_k}{\alpha_k}\psi_k \left[ \left( \frac{x_k}{\gamma_k} + 1 \right)^{\alpha_k} - 1 \right] + \frac{\psi_1}{\alpha_1}x_1^{\alpha_1} \label{utilkt}
\end{equation}

\noindent
where $\gamma_k > 0$, $\psi_k > 0$ and $\alpha_k \leq 1$ for all $k$ are required for this specification to be consistent with the properties of a utility function (@bhatmultiple2008). @bhatmultiple2008 provides a detailed overview of the parameter interpretation and in brief

- The $\psi_k$ parameters represent the marginal utility of consuming alternative $k$ at the point of zero consumption (i.e. baseline marginal utility).
- The $\gamma_k$ parameters are translation parameters that allow for corner solutions (i.e. zero consumption levels for alternatives) and also influence satiation. The lower the value of $\gamma_k$, the greater the satiation effect in consuming $x_k$.
- The $\alpha_k$ parameters control the rate of diminishing marginal utility of additional consumption. If $\alpha_k$ equal to one, then there is no satiation effects (i.e. constant marginal utility).

The 'random utility' element of the model is introduced into the baseline utility through a random error term as

\begin{equation}
\psi_k=\psi(z_k,\varepsilon_k)= exp(\beta'z_k+\varepsilon_k)
\end{equation}

\noindent
where $z_k$ is a set of variables that can include alternative-specific attributes and individual-specific characteristics, and $\varepsilon_k$ is an error term that allows for the utility function to be random over the population. We assume an extreme value distribution that is independently distributed across alternatives for $\varepsilon_k$ with an associated scale parameter of $\sigma$. For identification, we specify $\psi_1= e^{\varepsilon_1}$.

To ensure the estimated utility function corresponds to economic theory we specify $\gamma_k = exp(\gamma_k)$ such that $\gamma_k > 0$ and $\alpha_k = exp(\alpha_k)/(1 + exp(\alpha_k))$ such that $0 < \alpha_k < 1$. Weak complementarity, which is required for deriving unique welfare measures (@malerenvironment1974), is imposed in this specification by adding and subtracting one in the non-numeraire part of the utility function.

While the most general form of the MDCEV model includes $\psi_k$, $\gamma_k$, and $\alpha_k$ parameters for each alternative, Bhat (2008) discusses the identification concerns regarding estimating separate $\gamma_k$ and $\alpha_k$ parameters for each non-numeraire alternative. Typically only a subset of these parameters can be identified and there are three common utility function specifications:

1. $\alpha$-profile: set all $\gamma_k$ parameters to 1.

\begin{equation}
U(x_k, x_1) = \sum_{k=2}^{K} \frac{1}{\alpha_k}exp(\beta'z_k+\varepsilon_k) \left[ \left( x_k + 1 \right)^{\alpha_k} - 1 \right] + \frac{exp(\varepsilon_1)}{\alpha_1}x_1^{\alpha_1}
\end{equation}

2. $\gamma$-profile: set all non-numeraire $\alpha_k$ parameters to 0.

\begin{equation}
U(x_k, x_1) = \sum_{k=2}^{K} \gamma_k exp(\beta'z_k+\varepsilon_k) \ln\left( \frac{x_k}{\gamma_k} + 1 \right) + \frac{exp(\varepsilon_1)}{\alpha_1}x_1^{\alpha_1}
\end{equation}

3. hybrid-profile: set all $\alpha_k=\alpha_1=\alpha$.

\begin{equation}
U(x_k, x_1) = \sum_{k=2}^{K} \frac{\gamma_k}{\alpha} exp(\beta'z_k+\varepsilon_k) \left[ \left( \frac{x_k}{\gamma_k} + 1 \right)^{\alpha} - 1 \right] + \frac{exp(\varepsilon_1)}{\alpha}x_1^{\alpha}
\end{equation}

The likelihood function representing the model probability of the consumption pattern where $M$ goods are chosen can be expressed as @bhatmultiple2008

\begin{equation}
\label{eq:ll_base}
P(x^{*}_1,x^{*}_2...x^{*}_M,0,...,0) = \frac{1}{\sigma^{M-1}} \left(\prod_{m=1}^M c_m \right)\left(\sum_{m=1}^M \frac{p_m}{c_m} \right) \left( \ \frac{\prod_{m=1}^M e^{V_m/\sigma}}{ \left( \sum_{k=1}^J e^{V_k/\sigma} \right)^M }\right)(M-1)!
\end{equation}

\noindent
where $\sigma$ is the scale parameter and $c_m = \frac{1-\alpha_m}{x_m+ \gamma_m}$. The $V$ expression depend on what model specification is used:

1. $\alpha$-profle: $V_k = \beta' z_k + (\alpha_k-1)\ln\left( x_k + 1 \right) - \ln \left(p_k\right)$ for $k \geq 2$, and $V_1 = (\alpha_1-1)\ln(x_1)$.

2. $\gamma$-profle: $V_k = \beta' z_k - \ln\left( \frac{x_k}{\gamma_k} + 1 \right) - \ln \left(p_k\right)$ for $k \geq 2$, and $V_1 = (\alpha_1-1)\ln(x_1)$.

3. hybrid-profile: $V_k = \beta' z_k + (\alpha-1)\ln\left( \frac{x_k}{\gamma_k} + 1 \right) - \ln \left(p_k\right)$ for $k \geq 2$, and $V_1 = (\alpha-1)\ln(x_1)$.

In these specifications, the parameters ($\beta, \alpha_k , \gamma_k, \sigma$) are structural parameters that are assumed to be equal across the population which simplifies estimation. However, this fixed MDCEV specification is quite restrictive as it imposes that all individuals have the same tastes for altenatives (i.e. preference homeogeneity). This assumption is relaxed in the next two specifications.


## Latent class (LC-MDCEV) models

The latent class version of the MDCEV assumes that an individual belongs to a finite mixture of $S$ segments each indexed by $s$ ($s=1,2,...S$) [@sobhanilatent2013; @kuriyamalatent2010]. We do not observe which segment an individual belongs to but we can attribute a probability $\pi_{is}$ that individual $i$ is a member of segment $s$. We impose that $0 \leq \pi_{is} \leq 1$ and $\sum^S_{s=1} \pi_{is} = 1$ through the use of the logit link function as

\begin{equation}
\pi_{is} = \frac{exp(\delta_s'w_i)}{\sum^S_{s=1}exp(\delta_s'w_i)}
\end{equation}

\noindent
where $w_i$ is a vector of individual characteristics and $\delta_s$ is a vector of coefficients to be estimated. The $\delta_s$ coefficients determine how the individual characteristics affect the membership of individual $i$ in segment $s$. For identification, the $\delta_1$ coefficients for the first segment are set to zero.

The likelihood function can be written as

\begin{equation}
P = \prod_{i} \pi_{is}P_{is}
\end{equation}

where $P_{is}$ has the same form as Equation (\ref{eq:ll_base}) but is now class specific.

## Random parameters (RP-MDCEV) models

The random parameter specification of the MDCEV model assumes that the structural parameters $\theta =  (\beta, \alpha_k , \gamma_k)$ are not neccesarily fixed but have an assumed distribution [@bhatmultiple2008]. In **rmdcev**, parameters are distributed multivariate normal with a mean $\bar{\theta}$ and variance covariance matrix $\sum_{\theta}$ [@vonhaefenkuhn-tucker2005]. This structure allows for continuous preference heterogeneity and accomodates more fleixlbe correlation patterns between alternatives in a simlar fashion to the mixed logit model in discrete choice models. The $\sigma$ parameter is always assumed to be a fixed parameter.

The most flexible model specification is to estimate the full variance covariance matrix and if there are $Q$ parameters in $\theta$ then there are $Q(Q+1)/2$ unique variance covariance parameters to estimate in the correlated RP-MDCEV specification. An alternative is to assume the off-diagonal parameters are zero and estimate uncorrelated random parameters by estimating the $Q$ diagonal elements of $\sum_{\theta}$. If all elements of $\sum_{\theta}$ are assumed to be zero, the model collapses to the fixed MDCEV structure.

## A note on Bayesian versus classiscal maximum likelihood estimation

The MDCEV model without unobserved heterogeneity can be estimated using Bayesian or classical maximum likelihood techniques. The LC-MDCEV model can only be estimated using classical maximum likelihood techniques as Bayesian approaches are challenged by the 'label switching' problem. The RP-MDCEV models can only be estimated using Bayesian techniques as random parameter models require simulated maximum likelihood estimators and these are not implemented in **rmdcev** at this time.

While there are philosphical differences between Bayesian and classical maximum likelihood techniques to estimating models, the Bernstein-von Mises theorem suggests that the Bayesian posterior distribution are asymptotically equivalent to maximum likelihood estimates if the data generating process has been correctly specified [@traindiscrete2003].

# The rmdcev package {#rmdcev}

## Data format

The **rmdcev** package accepts data in "long" format (i.e. one row per available non-numeraire alternative for each individual). There is no row for the numeraire good. If there are $I$ individuals and $J$ non-numeraire goods, then the data frame should have $IxJ$ rows. The following named columns are required in the data:

- **id**: The unique id variable for each individual
- **good**: The variable containing the good number
- **quant**: Consumption levels for each good
- **price**: Price levels for each good
- **income**: Income level for each individual

Additional variables containing information for alternative-specific attributes and individual characteristics can also be included. Data must be arranged by id and then good. As an example, we can load the recreation data incorporated with the package. This data is from the Value of Nature to Canadians Survey and includes choices for number of days spent recreating in 17 different outdoor activities for 2,000 people [@federal20122014].

```{r, echo=T, data}
data(data_rec, package = "rmdcev")
data_rec
```
In additional to the recreation behaviour and prices, the data includes information on three individual characteristics: university (a dummy variable if the person has completed a university degree), ageindex (a person's age divided by the average age in sample), and urban (a dummy variable if a person lives in an urban area). Additional details on the data and price construction are provided in @lloydsmitheconomics2019. The names for each activity are provided in the good_name column. We can summarize the average consumption and price levels for each good as:

```{r, echo=T, summary}
data_rec %>%
	group_by(good, good_name) %>%
	summarise(mean_quant = mean(quant),
			      mean_price = mean(price))
```

## MDCEV estimation

###	A general overview of FitMDCEV

All the various MDCEV model specifications are estimated using the **FitMDCEV** function.

```{r, echo=T, fitmdcev}
args(FitMDCEV)
```

The main arguments are briefly explained below:

- **data** The ($IxJ$) data to be used in estimation as described above.

- **psi_formula**: Formula for the $z_k$ variables in psi. This formula is based on the R package **Formula** [@zeileisextended2010]. The formula will automatically include a constant but a constant can be omitted if -1 is used in the formula.

```{r, echo=T, formula}
psi_formula = ~ z1 + z2 + z3
```

- **lc_formula** Formula for membership equation if a latent class model is specified. The syntax follows the R package **Formula**.

- **weights** An optional vector of sampling or frequency weights.

- **model** A string indicating which model specification to estimate. The four options are presented below:
	+ "alpha": $\alpha$-profile with all $\gamma_k$ parameters fixed equal to 1.
	+ "gamma": $\gamma$-profile with one estimated $\alpha_1$ and all non-numeraire $\alpha_k$ parameters equal to 0.
	+ "hybrid": hybrid-profile with a single estimated $\alpha$ parameter (i.e. $\alpha_1 = \alpha_k = \alpha$).
	+ "hybrid0": hybrid-profile with all $\alpha$ parameters fixed equal to 1e-3.


- **n_classes** The number of latent classes.

- **fixed_scale1** Whether to fix the scale parameter at 1.

- **trunc_data** Whether the estimation should be adjusted for truncation. This option should be used if data was only collected from people that consume at least one non-numeraire alternative. For example, if a intercept survey collected recreation data at a park then people that did not visit the park are not included in the data.

- **seed** Random seed.

- **algorithm** Either "Bayes" for Bayesian estimation or "MLE" for maximum likelihood estimation. The MLE algorithm uses the Limited-memory BFGS which approximates the Broyden–Fletcher–Goldfarb–Shanno (BFGS) algorithm but uses less computer memory.

- **flat_priors** indicator if completely uninformative priors should be specified. If using MLE, the optimizing function will then be equal to log-likelihood. Defaults to 1 if MLE used and 0 if Bayes used.

- **print_iterations** Whether to print itermediate iteration information or not.

- **std_errors** Compute standard errors using the delta method ("deltamethod") or multivariate normal draws ("mvn").

- **n_draws** The number of multivariate normal draws for standard error calculations.

- **initial.parameters** Specify initial parameters instead of starting at random.

### Estimating MDCEV using maximum likelihood techniques

We estimate a MDCEV model using the **Recreation** data where we include activity-specific constants in $\psi$. We can use the following code to create these indicator variables for each activity. Note that we can also use the "factor(good_name)" command directly in the formula but the names are then quite long.

```{r, echo=T, create_dummies}
data_rec <- data_rec %>%
  mutate(v = 1, yr = good_name) %>%
  tidyr::spread(yr, v, fill = 0) %>%
	arrange(id, good)

psi_formula <- ~ beach + birding + camping + cycling + fish + garden + golf +
                 hiking + hunt_birds + hunt_large + hunt_trap + hunt_waterfowl +
				 motor_land + motor_water + photo + ski_cross + ski_down -1

```

We specify the hybrid model specification where a single $\alpha$ is estimated for the numeraire and non-numeraire alternatives by setting **model = "hybrid"**. We use maximum likelihood estimation by setting **algorithm = "MLE"**. Standard errors can be calculated using the delta method using the **std_errors** option as shown below. For these examples we are going to use a subset of 200 individuals from the data.

The syntax for the model is the following:

```{r, echo=T, estimation_mdcev_hybrid}
mdcev_mle <- FitMDCEV(psi_formula = psi_formula,
                        data = subset(data_rec, id < 201),
                        model = "hybrid",
                        algorithm = "MLE",
					  	std_errors = "deltamethod",
                        print_iterations = FALSE)
```

The function first checks to ensure the data has the necessary variables, is arranged properly, and that all individuals spend positive amounts on the numeraire good. If the data passes these checks, the model is then estimated. Setting **print_iterations = TRUE** will print out intermediate iteration results as the model converges.

The output of the function can be accessed by calling SummaryMDCEV.

```{r, echo=T,summary_mdcev_hybrid}
SummaryMDCEV(mdcev_mle)
```

The summary includes overall model and estimation information and the parameter estimates.

In the next example, we estimate the $\alpha$-profile of the utility function by changing the model argument to **"alpha"**.

```{r, estimation_mdcev_alpha, message = FALSE, warning = FALSE}
mdcev_mle <- FitMDCEV(psi_formula = psi_formula,
                    data = subset(data_rec, id < 201),
                    model = "alpha",
                    algorithm = "MLE",
				  	std_error = "deltamethod",
                    print_iterations = FALSE)
```

```{r, echo=T, echo=T,summary_mdcev_alpha}
SummaryMDCEV(mdcev_mle)
```

The parameter estimates are quite different from the previous model as all the non-numeraire $\gamma$ parameters are fixed at 1 and alternative-specific $\alpha_k$ parameters are estimated.

The $\gamma$-profile version of the model can be estimated by changing the model to **"gamma"** as the next example demonstrates.

```{r, estimation_mdcev_les, message = FALSE, warning = FALSE}
mdcev_mle <- FitMDCEV(psi_formula = psi_formula,
                    data = subset(data_rec, id < 201),
                    model = "gamma",
                    algorithm = "MLE",
				  	std_error = "deltamethod",
                    print_iterations = FALSE)
```

```{r,  echo=T,summary_mdcev_les}
SummaryMDCEV(mdcev_mle)
```

The same number of parameters are estimated in all three models and the log-likelihood is highest for the $\gamma$-profile specification.

### Estimating MDCEV using Bayesian techniques

The exact same models can be fit using Bayesian estimation by changing the algorithm call to **"Bayes"**. Bayesian estimation is implemented using the Stan programming language [@carpenterstan2017]. The Bayesian framework requires careful choice of priors for the parameters. All priors are assumed to follow a normal distribution with a fixed mean and the user can change the standard deviation through these options in the FitMDCEV function.

- **prior_psi_sd** standard deviation for normal prior with mean 0.
- **prior_gamma_sd** standard deviation for normal prior with mean 0.
- **prior_alpha_sd** standard deviation for normal prior with mean 0.5.
- **prior_scale_sd** standard deviation for normal prior with mean 1.

There are also a number of further options for Bayesian estimation. For example, the number of iterations (n_iterations), number of chains (n_chains), and number of cores (n_cores) for parallel implementation of the chains can also be chosen. The full set of options for Bayesian estimation are presented below.

- **random_parameters** The form of the covariance matrix for the parameters. Options are
	+ 'fixed' for no random parameters,
	+ 'uncorr for uncorrelated random parameters, and
	+ 'corr' for correlated random parameters.
	
- **n_iterations** The number of iterations in Bayesian estimation.

- **n_chains** The number of chains in Bayesian estimation.

- **n_cores** The number of cores to use in Bayesian estimation. Can set using options(mc.cores = parallel::detectCores()).

- **max_tree_depth** http://mc-stan.org/misc/warnings.html#maximum-treedepth-exceeded

- **adapt_delta** http://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup

- **lkj_shape_prior** Prior for Cholesky matrix for correlated random parameters

In this example, we estimate the hybrid0 specification using Bayesian techniques. We set the number of iterations to 200 and use 4 independent chains.

```{r,eval=T, echo=T, estimation_mdcev_bayes, message = FALSE, warning = FALSE}
mdcev_bayes <- FitMDCEV(psi_formula = psi_formula,
                        data = subset(data_rec, id < 201),
                        model = "hybrid0",
                        algorithm = "Bayes",
                        n_iterations = 200,
                        n_chains = 4,
                        print_iterations = FALSE)
```

The output of the function can be accessed by calling SummaryMDCEV.

```{r,eval=T, echo=T, summary_mdcev_bayes}
	SummaryMDCEV(mdcev_bayes)
```


One benefit of using the Bayesian approach is that we can take advantage of the postestimation commands, interactive diagnostics, and posterior analysis in **rstan**, [**bayesplot**](https://mc-stan.org/bayesplot/) [@gabrybayesplot2019], and [**shinystan**](http://mc-stan.org/shinystan/) [@muthuser2018]. For example, the effective sample size reports the estimated number of independent draws from the posterior distribution for each parameter [@stan2019]. The interested reader is refered to these packages for additional details.

### Estimating LC-MDCEV models

In this example, we estimate a LC-MDCEV model using the **Recreation** data. We set the number of classes equal to 2 and we use data on 500 individuals. We would like to include the **university**, **ageindex**, and **urban** in the membership equation and we include them in the **lc_formula** interface. Note that we need to include at least a constant in the formula. The LC model is automatically estimated as long as the prespecified number of classes (**n_classes**) is set greater than 1.

```{r, estimation_mdcev_lc, message = FALSE, warning = FALSE}
mdcev_lc <- FitMDCEV(psi_formula = psi_formula,
	                  lc_formula = ~ university + ageindex + urban,
	                  data = subset(data_rec, id < 501),
	                  n_classes = 2,
	                  model = "hybrid0",
	                  algorithm = "MLE",
	                  print_iterations = FALSE)
```

```{r, summary_mdcev_lc}
	SummaryMDCEV(mdcev_lc)
```

In this LC example, we assume that there are two types of people that have different preferences for recreation. The probability of class assignment depends on unobserved factors and the three sociodemographic factors included in the membership equation. The summary output reports the average class probabiliies as being 32% for class 1 and 68% for class 2. The $\psi$ parameters across classes are similar although there are some noticable differences. The $\gamma$ parameters, on the other hand, show that satiation between classes is quite different between the classes. To assist speed and convergence issues, **rmdcev** uses the results of the MDCEV model as starting values when estimating the LC-MDCEV model. The MDCEV model output can be accessed from **mdcev_lc[['mdcev_fit']]** object for comparison.

### Estimating RP-MDCEV models

Random parameter models require defining and parameterizing the variance covariance matrix. For uncorrelated random parameters, the diagonal elements of the variance covariance matrix are estimated and the off-diagonal elements are assumed to be zero. For correlated random parameters, the variance covariance matrix is fully estimated and can be parameterized in many ways. The **rmdcev** package defines the variance covariance matrix in terms of Cholesky factors of the correlation matrix and a vector of standard deviations for numerical stability. Thus the variance covariance matrix is specified as

\begin{equation}
\sum = diag(\tau) \; x \; LL^T \; x \; diag(\tau)
\end{equation}

where $\tau$ is a vector of standard deviations, and $L$ is the cholesky factors of the correlation matrix.

In this example, we estimate an uncorrelated random parameters MDCEV model using **rmdcev**. We set the argument **random_parameters = "uncorr"** to indicate that uncorrelated random parameters will be estimated. All random parameters follow a normal distribution. We change the **psi_formula** specification to only include a single constant term and fix the scale parameter at 1 using **fixed_scale1 = 1**.

```{r,eval=T, echo=T, estimation_mdcev_rp, message = FALSE, warning = FALSE}
mdcev_rp <- FitMDCEV(psi_formula = ~ 1,
					data = subset(data_rec, id < 201),
					model = "hybrid0",
					algorithm = "Bayes",
					n_chains = 4,
					fixed_scale1 = 1,
					n_iterations = 200,
					random_parameters = "uncorr",
					print_iterations = FALSE)
```


```{r, eval=T, summary_mdcev_rp}
	SummaryMDCEV(mdcev_rp)
```

The results show the means of the random parameters followed by the estimated standard deviations. The standard deviations that are estimated to be different from zero suggest there is heterogeneity in preference parameters. The correlated random parameters specification can be estimated by setting **random_parameters = "corr"**. 

## Simulating MDCEV demand and welfare scenarios

The **rmdcev** package includes simulation functions for calculating welfare measures and forecasting demand under alternative policy scenaros. I first provide an overview of the approach used for simulation and then provide code examples.

### Overview of simulation steps

Once the model parameters are estimated, there are two steps to simulation in MDCEV models. In the first step we draw simulated values for the unobserved heterogeneity term ($\varepsilon$) using Monte Carlo techniques. The second step uses these error draws, the previously estimated model parameters, and the underlying data to calculate Marshallian demands for forecasting or Hicksian demands for welfare analysis. These two steps are described below.

**Step 1: simulating unobervered heterogeneity**

Monte Carlo simulation techniques can be employed to draw simulated values of the unobserved heterogeneity ($\varepsilon$) using either unconditional or conditional draws.

1. Unconditional error draws: draw from the entire distribution of unobserved heterogeneity using the following formula

\begin{equation}
\varepsilon_{k} = -log(-log(draw(0,1)))) * \sigma
\end{equation}

where $draw(0,1)$ is a draw between 0 and 1 and $\sigma$ is the scale parameter.**rmdcev** allows errors to be drawn using uniform draws or the Modified Latin Hypercube Sampling algorithm (@hesson2006).

2. Conditional error draws: draw errors terms to reflect behaviour and dependent on whether alternative is consumed or not [@vonhaefenincorporating2003; @vonhaefenestimation2004]:

- If $x_k>0$, set  $\varepsilon_k = (V_1 - V_k)/ \sigma$ where $V_1$ and $V_k$ depend on the model specification as detailed above.
- If $x_k=0$, $\varepsilon_k < (V_1 - V_k)/ \sigma$ and simulate $\varepsilon_k$ from the truncated type I extreme value distribution such that

\begin{equation}
\varepsilon_k = -log(-log(draw(0, 1) * exp(-exp(\frac{V_1 - V_k}{\sigma})))) * \sigma
\end{equation}

In the conditional error draw approach, we normalize $\varepsilon_1=0$. 

The main differences between these two error draw approaches is that in the conditional approach, we draw errors such that the model perfectly predicts the observed consumption patterns in the baseline state [@vonhaefenkuhn-tucker2005]. Thus the conditional approach uses observed behaviour by individuals to characterize unobserved heterogeneity. If the model correctly specifies the data generating process, the sample means of the conditional and unconditional approaches should converge in expectation. Another difference between the two approaches is that the unconditional approach uses more computation time. The reason for the relative slowness of the unconditional approach is the need to calculate consumption patterns in the baseline state as well as simulate the entire distribution of unobserved heterogeneity.

**Step 2: Calculating welfare measures and demand forecasts**

With the error draws in hand, the second step is to simulate demand or welfare changes. Compared to welfare measures in discrete choice models, welfare calculation in MDCEV models is more challenging because of the two Kuhn-Tucker conditions in Equation (\ref{eq:kt_conditions}). For a given policy scenario, a priori, we do not know which alternatives have a positive or zero consumption level. **rmdcev** implements the @pinjaricomputationally2011 efficient demand forecasting routine for simulating demand behaviour which relies on calculting Marshallian demands. For welfare calculations, we need to calculate the expenditure function in \ref{eq:welfare} which relies on Hicksian demands. These are calculated using the approach described by @lloydsmithnew2018. The demand and welfare simulation approaches share a lot of commonalities and thus I only fully describe the approach for welfare calculations below. The specific steps for demand simulation is explained in-depth in @pinjaricomputationally2011 and the interested reader is encouraged to read Section 4 of the paper for the exact details.

### Welfare analysis

For the welfare analysis, I first fully describe the specific steps of the algorithm and then demonstrate its use in an example. There are two alogrithms that differ depending on the MDCEV model specification. If a single $\alpha$ parameter is estimated (i.e. model = "hybrid" or "hybrid0"), then we can use the hybrid approach to welfare simulation. If there are heterogenous $\alpha$ parameters, then we can use the general approach to welfare simulation. The hybrid approach is less computationally intensive and provides an exact analytical solution but the general approach can be used with all utility specifications. The specific steps for both algorithms are described below. 

**Steps in algorithm for hybrid-profile utility specifications**

**Step 0**: Assume that only the numeraire alternative is chosen and let the number of chosen alternatives equal one (M=1).

**Step 1**: Using the data, model parameters, and either conditional or unconditional simulated error term draws, calculate the price-normalized baseline utility values ($\psi_k/p_k$) for all alternatives. Sort the $K$ alternatives in the descending order of their price-normalized baseline utility values. Note that the numeraire alternative is in the first place. Go to step 2. 

**Step 2**: Compute the value of $\lambda^E$ using the following equation:

\begin{equation}
\frac{1}{\lambda^E} = \left[ \frac{\alpha \bar{U} + \sum_{m=2}^{M} \gamma_m \psi_m} {\sum_{m=2}^{M} \gamma_m \psi_m \left( \frac{p_m}{\psi_m} \right)^\frac{\alpha}{\alpha-1} + \psi_1 \left(\frac{p_1}{\psi_1} \right)^\frac{\alpha}{\alpha-1}} \right] ^\frac{\alpha-1}{\alpha}
\end{equation}

Go to step 3.

**Step 3**: If $\frac{1}{\lambda^E} > \frac{\psi_{M+1}}{p_{M+1}}$, go to step 4. Else if $\frac{1}{\lambda^E} < \frac{\psi_{M+1}}{p_{M+1}}$, set $M = M + 1$. If $M < K$, go back to step 2. If $M = K$, go to step 4.

**Step 4**: Compute the optimal Hicksian consumption levels for the first $I$ alternatives in the above descending order using the following equations

\begin{align}
\label{eq:optimal_x}
x_1 &=   \left( \frac{p_1}{\lambda^E \psi_1} \right)^\frac{1}{\alpha_1-1}\text{, and} \\
x_m &=   \left[ \left( \frac{p_m}{\lambda^E \psi_m} \right)^\frac{1}{\alpha_m-1}-1 \right]\gamma_m, \; \; \text{if} \; \; x_m > 0.
\end{align}

Set the remaining alternative consumption levels to zero and stop.

**Steps in algorithm for general utility specifications**

In this context, there is no closed-form expressions for $\lambda^E$ and we need to conduct a numerical bisection routine. Let $\hat{\lambda^E}$ and $\hat{U}$ be estimates of $\lambda^E$ and $U$ and let $tol_{\lambda}$ and $tol_{U}$ be the tolerance levels for estimating $\lambda^E$ and $U$ that can be arbitrarily small. The algorithm works as follows:

**Step 0**: Assume that only the numeraire is chosen and let the number of chosen alternatives equal one (M=1).

**Step 1**: Using the data, model parameters, and either conditional or unconditional simulated error term draws, calculate the price-normalized baseline utility values ($\psi_k/p_k$) for all alternatives. Sort the $K$ alternatives in the descending order of their price-normalized baseline utility values. Note that the numeraire is in the first place. Go to step 2.

**Step 2**: Let $\frac{1}{\hat{\lambda^E}} = \frac{\psi_{M+1}}{p_{M+1}}$ and substitute $\hat{\lambda^E}$ into the following quation to obtain an estimate of $\hat{U}$.

\begin{align}
\bar{U}=\sum_{M=2}^{M} \frac{\gamma_m}{\alpha_m}\psi_m \left[ \left( \frac{p_m}{\lambda^E \psi_m} \right)^\frac{\alpha_m}{\alpha_m-1} - 1 \right] + \frac{\psi_1}{\alpha_1}\left(\frac{p_1}{\lambda^E \psi_1} \right)^\frac{\alpha_1}{\alpha_1-1}.
\end{align}

**Step 3**: If $\hat{U} < \bar{U}$, go to step 4. Else, if $\hat{U} \geq \bar{U}$, set $\frac{1}{\lambda_l^E}= \frac{\psi_{M+1}}{p_{M+1}}$ and $\frac{1}{\lambda_u^E}= \frac{\psi_{M}}{p_{M}}$. Go to step 5.

**Step 4**: Set $M=M+1$. If $M<K$, go to step 2. Else if $M=K$, set $\frac{1}{\lambda_l^E}= 0$ and $\frac{1}{\lambda_u^E}= \frac{\psi_{K}}{p_{K}}$. Go to step 5.

**Step 5**: Let $\hat{\lambda^E}= (\lambda_l^E+\lambda_u^E)/2$ and substitute $\hat{\lambda^E}$ into the equation of step 2 to obtain an estimate of $\hat{U}$. Go to step 6.

**Step 6**: If $|\lambda_l^E-\lambda_u^E| \leq \; tol_{\lambda}$ or $|\hat{U}-\bar{U}| \leq \; tol_{U}$, go to step 7. Else if $\hat{U}<\bar{U}$, update $\lambda^E_u= (\lambda_l^E+\lambda_u^E)/2$ and go to step 5. Else if $\hat{U}>\bar{U}$, update $\lambda^E_l= (\lambda_l^E+\lambda_u^E)/2$ and go to step 5.

**Step 7**: Compute the optimal Hicksian consumption levels for the first $M$ alternatives in the above descending order using Equation (\ref{eq:optimal_x}). Set the remaining alternative consumption levels to zero and stop.


#### Welfare calculation example

In **rmdcev**, the functions for welfare and demand simulation have been divided into 3 steps to allow users to parallelize operations as desired. 

##### 1. Define policy scenarios 

In the first step, we define the number of alternative policy scenarios to use in simulation and then specify changes to the $\psi$ variables and prices of alternatives. The CreateBlankPolicies function has been created to easily set-up the required lists for the simulation. These policies can then be manually edited according to the specific policy scenario. For prices, **rmdcev** is set up to accept additive changes in prices that impact all individuals the same. For the $\psi$ variable changes, the package is set up to accept any new values for these variables. Depending on the number of individuals and number of policies, the generated policies list can be quite large. If the user is only interested in assessing price changes, then I recommend setting **price_change_only = TRUE** which ensures duplicate $\psi$ data is not created.

In this example, we are interested in two separate policies. The first policy increases the costs of all recreation activities by \$1 and the second policy increases the cost of all hunting activities by \$10. The policy set-up for these two scenarios is demonstrated below.

```{r, sim_mdcev_welfare_policy}
ngoods <- mdcev_mle$stan_data[["J"]]
npols <- 2

policies<-  CreateBlankPolicies(npols = npols, 
								ngoods = ngoods, 
								mdcev_est$stan_data[["dat_psi"]], 
								price_change_only = TRUE)

policies$price_p[[1]] <- c(0, rep(1, ngoods))
policies$price_p[[2]][10:13] <- rep(10, 4)
```

##### 2. Prepare simulation data

The second step is to combine the parameter estimates, data, and policy scenarios into a data format for simulation. The PrepareSimulationData function uses the model fit and the user defined policy scenarios to create this specific data format. This function separates the output into individual-specific data (df_indiv), data common to all individuals (df_common), and simulation options (sim_options).

```{r, sim_mdcev_welfare_prepare}
df_sim <- PrepareSimulationData(mdcev_mle, policies)
```

##### 3. Simulate MDCEV model 

The third step is to simulate the policy scenario using the formatted data. The user chooses the type of error draws (unconditional or conditional as described above), the number of error draws, and whether to simulate the demand or welfare changes. Note that the first time SimulateMDCEV is run in each session, the C++ simulation code is compiled and this can take approximately 30 seconds. Subsequent function calls do not require the code to be recompiled.


```{r, eval=T, sim_mdcev_welfare}
welfare <- SimulateMDCEV(df_sim$df_indiv,
					 df_common = df_sim$df_common,
					 sim_options = df_sim$sim_options,
					 cond_err = 1, 
					 nerrs = 15, 
					 sim_type = "welfare")
SummaryWelfare(welfare)
```

The output of the SimulateMDCEV for welfare analysis is a list of matrices where each element of the list is for an individual and the matrix consists of rows for each policy scenario and columns for each parameter simulation. Note that if a LC-MDCEV model is estimated, there will be one list of matrices for each class.

The SummaryWelfare function computes summary statistics across all individuals. For example, the average welfare change for a \$1 daily increase in all recreation costs is -\$129.

The reason these last two steps are separate is to allow users to parallelize the simulation step as the last step can be computationally intensive. The number of simulations is a multiplicative function of the number of individuals, number of policies, number of parameter estimate simulations, and the number of error draws ($I$ x $npols$ x $nsims$ x $nerrs$). Even for modestly sized data, the total number of simulations can easily reach well into the millions or billions. All simulations are conducted at the individual level which allows the user to easily parallelize the SimulateMDCEV function using the **parallel** package or similar packages.

### Demand forecasting

This section demonstrates the demand forecasting capabilities of **rmdcev**. Please refer to the previous section for an overview of the three steps to simulation. 

```{r, eval=T, sim_mdcev_demand}
policies <-	CreateBlankPolicies(npols = 2, 
								ngoods = mdcev_mle$stan_data[["J"]], 
								mdcev_mle$stan_data[["dat_psi"]], 
								price_change_only = TRUE)

policies$price_p[[1]] <- c(0, rep(1, ngoods))
policies$price_p[[2]][10:13] <- rep(10, 4)
df_sim <- PrepareSimulationData(mdcev_mle, policies)

demand <- SimulateMDCEV(df_sim$df_indiv, 
						df_common = df_sim$df_common, 
						sim_options = df_sim$sim_options,
					 	cond_err = 1, 
						nerrs = 20, 
						sim_type = "demand")
SummaryDemand(demand)

```

The output of the demand simulation is a list of $I$ elements, one for each individual. Within each element there are nsim lists each containing a matrix of demands. The rows of the matrix are for each policy scenario and the columns represent each alternative. The SummaryDemand function computes summary statistics.

## Creating simulated MDCEV data

Simulated MDCEV data can be easilty created for model assessment and Monte Carlo analysis. To demonstrate this functionality of **rmdcev**, we can generate some fake data for 1,000 individuals with 10 non-numeraire alternatives and the following parameter values.

```{r, eval=T, fake_simulate}
model <- "hybrid"
nobs <- 1000
ngoods <- 10
sim.data <- GenerateMDCEVData(model = model, 
								nobs = nobs, 
								ngoods = ngoods,
								alpha_parms = 0.5, 
								scale_parms = 1,
								gamma_parms = stats::runif(ngoods, 1, 2), 
								psi_i_parms = c(-1.5, 3, -2, 1, 2), 
								psi_j_parms = c(-5, 0.5, 2))
```

Next, we estimate the MDCEV model using maximum likelihood to recover the parameter estimates.

```{r, fake_estimate, message = FALSE, warning = FALSE}
mdcev_est <- FitMDCEV(psi_formula = ~ b1 + b2 + b3 + b4 + b5 + b6 + b7 + b8 - 1,
				   data = sim.data$data,
				   model = model,
				   algorithm = "MLE",
				   print_iterations = FALSE)
```

We can compare the estimated parameters from the models with the true values. As shown below, the model is successful at recovering the parameters for the simulated data.

```{r, eval=T, fake_compare}
parms_true <- tbl_df(sim.data$parms_true) %>%
	mutate(true = as.numeric(true))

coefs <- mdcev_est$est_pars %>%
	mutate(parms = gsub("\\[|\\]", "", parms)) %>%
	group_by(parms) %>%
	summarise(mean = mean(value),
			  sd = sd(value),
			  zstat = mean / sd,
			  cl_lo = quantile(value, 0.025),
			  cl_hi = quantile(value, 0.975)) %>%
	left_join(parms_true, by = "parms") %>%
	print(n=200)
```

# Conclusions {#conclusions}

The **rmdcev** package implements the multiple discrete-continuous extreme value model with heterogeneity that can be continuous (i.e. random parameters) or discrete (i.e. latent classes). Models can be estimated using maximum likelihood or Bayesian techniques. This paper demonstrates the use of the pacakage to estimate several model specifications and to derive demand forecasts and welfare implications of policy scenarios. To my knowledge, there is no other available statistical package that can estimate welfare implications of policy scenarios using MDCEV models. I hope that the publication of **rmdcev** will make MDCEV modeling available to a wider audience.

# References
